{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. input files\n",
    "2. load data in that line\n",
    "3. save data\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 xspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_dict2df(savepath, regname, mdl, bigkeys = ['T', 'Z', 'n']):\n",
    "    # initialize dict\n",
    "    output_dict = {'reg':[], 'cstat':[], 'dof':[]}\n",
    "    for name in bigkeys:\n",
    "        output_dict[f'{name}-errlo'] = []\n",
    "        output_dict[f'{name}-errhi'] = []\n",
    "        output_dict[f'{name}-value'] = []\n",
    "        output_dict[f'{name}-value'] = []\n",
    "    \n",
    "\n",
    "    cts = 0\n",
    "    dirs = glob(f'{savepath}/SDSS*')\n",
    "    for dir in dirs:\n",
    "        srcname = dir.split('/')[-1]\n",
    "        val_file = f'{dir}/fit_231115/logs/annu_{regname}_{mdl}_freepar.log'\n",
    "        err_file = f'{dir}/fit_231115/logs/annu_{regname}_{mdl}_chain1000_par.log'\n",
    "        cst_file = f'{dir}/fit_231115/logs/annu_{regname}_{mdl}_fit.log'\n",
    "\n",
    "        # read mcmc errors\n",
    "        if glob(val_file) and glob(err_file):\n",
    "            output_dict[f'reg'].append(f'{srcname}')\n",
    "            # read the annuli from eckert regionfile\n",
    "            with open(err_file) as f:\n",
    "                lines = f.readlines()\n",
    "            for i in range(len(bigkeys)):\n",
    "                if len(lines)> 20:\n",
    "                    errlo = 999\n",
    "                    errhi = 999\n",
    "                else:\n",
    "                    start_idx = next((index for index, line in enumerate(lines) if 'Parameter' in line), None)\n",
    "                    \n",
    "                    errlo = lines[int(start_idx+1+i)].split('(')[-1].split(',')[0]\n",
    "                    errhi = lines[int(start_idx+1+i)].split('(')[-1].split(',')[-1][:-2]\n",
    "                output_dict[f'{bigkeys[i]}-errlo'].append(abs(float(errlo)))\n",
    "                output_dict[f'{bigkeys[i]}-errhi'].append(float(errhi))\n",
    "\n",
    "            # read value\n",
    "            with open(val_file) as f:\n",
    "                text = f.read()\n",
    "            pattern = r'([+-]?[\\d]*\\.?[\\d]+(?:[eE][-+]?\\d+)?)\\s+\\+/-'\n",
    "            values = re.findall(pattern, text)\n",
    "            for i in range(len(bigkeys)):\n",
    "                output_dict[f'{bigkeys[i]}-value'].append(float(values[i]))\n",
    "            \n",
    "            # read cstat\n",
    "            with open(cst_file) as f:\n",
    "                lines = f.readlines()[-30:]\n",
    "            for line in lines:\n",
    "                if 'Total fit statistic' in line:\n",
    "                    cstat = float(line.split('tic')[1].split('with')[0].strip())\n",
    "                    dof = int(line.split('with')[-1].split('d.o.f')[0].strip())\n",
    "                    output_dict['cstat'].append(cstat)\n",
    "                    output_dict['dof'].append(dof)\n",
    "        else:\n",
    "            cts+=1\n",
    "            continue\n",
    "    print(cts)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 GDEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "my_rootdir = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP'\n",
    "\n",
    "new_dict = tidy_dict2df(my_rootdir, 'R500-01', 'GDEM',  bigkeys = ['T', 'Tsig', 'Z', 'n'])\n",
    "new_df = pd.DataFrame(new_dict)\n",
    "new_df.to_csv(f'{my_rootdir}/../dats/R500-01_GDEM_xspec.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 1T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "my_rootdir = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP'\n",
    "\n",
    "new_dict = tidy_dict2df(my_rootdir, 'R500-01', '1T',  bigkeys = ['T', 'Z', 'n'])\n",
    "new_df = pd.DataFrame(new_dict)\n",
    "new_df.to_csv(f'{my_rootdir}/../dats/R500-01_1T_xspec.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 spex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_dict2df(savepath, regname, mdl, bigkeys = ['T', 'Z', 'n']):\n",
    "    # initialize dict\n",
    "    output_dict = {'reg':[]}\n",
    "    for name in bigkeys:\n",
    "        output_dict[f'{name}-errlo'] = []\n",
    "        output_dict[f'{name}-errhi'] = []\n",
    "        output_dict[f'{name}-value'] = []\n",
    "        output_dict[f'{name}-value'] = []\n",
    "    \n",
    "\n",
    "    cts = 0\n",
    "    dirs = glob(f'{savepath}/SDSS*')\n",
    "    for dir in dirs:\n",
    "        srcname = dir.split('/')[-1]\n",
    "        val_file = f'{dir}/fit_spex_231115/logs/annu_{regname}_{mdl}_freepar.log'\n",
    "        err_file = f'{dir}/fit_spex_231115/logs/annu_{regname}_{mdl}_chain1000_par.log'\n",
    "        # read mcmc errors\n",
    "        if glob(val_file) and glob(err_file):\n",
    "            output_dict[f'reg'].append(f'{srcname}')\n",
    "            # read the annuli from eckert regionfile\n",
    "            with open(err_file) as f:\n",
    "                lines = f.readlines()\n",
    "            for i in range(len(bigkeys)):\n",
    "                if len(lines)> 20:\n",
    "                    errlo = 999\n",
    "                    errhi = 999\n",
    "                else:\n",
    "                    start_idx = next((index for index, line in enumerate(lines) if 'Parameter' in line), None)\n",
    "                    \n",
    "                    errlo = lines[int(start_idx+1+i)].split('(')[-1].split(',')[0]\n",
    "                    errhi = lines[int(start_idx+1+i)].split('(')[-1].split(',')[-1][:-2]\n",
    "                \n",
    "                output_dict[f'{bigkeys[i]}-errlo'].append(abs(float(errlo)))\n",
    "                output_dict[f'{bigkeys[i]}-errhi'].append(float(errhi))\n",
    "\n",
    "            # read value\n",
    "            with open(val_file) as f:\n",
    "                text = f.read()\n",
    "            pattern = r'([+-]?[\\d]*\\.?[\\d]+(?:[eE][-+]?\\d+)?)\\s+\\+/-'\n",
    "            values = re.findall(pattern, text)\n",
    "            for i in range(len(bigkeys)):\n",
    "                output_dict[f'{bigkeys[i]}-value'].append(float(values[i]))\n",
    "            \n",
    "        else:\n",
    "            cts+=1\n",
    "            # print(dir)\n",
    "            continue\n",
    "    print(cts)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 GDEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 1T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1302458d99d58fefb56dc0fec08d039cf240bdcae78a53a9226b7c46b3832fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
