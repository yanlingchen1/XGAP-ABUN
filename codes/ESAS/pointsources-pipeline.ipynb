{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Steps:\n",
    "\n",
    "###### ensure point sources position and size ######\n",
    "#### position\n",
    "1. extract as many point sources using cheese as possible.\n",
    "1.1 emlfill\n",
    "2. comb merge the mos1, mos2, pn images,\n",
    "3. blink check the missing point sources, add or sub the point sources ra,dec\n",
    "#### size\n",
    "3.1 create the new bkgregtdet/sky.fits using region commands\n",
    "4. region and makemask command\n",
    "# check the result if all the point sources size and radec are nice!\n",
    "\n",
    "###### determine the cutoff flux or SB by logN-S #####\n",
    "5. divide the region file into individual files\n",
    "6. extract spectra from the region, make logN-logS plot\n",
    "7. determine the excluded point sources cutoff flux\n",
    "\n",
    "###### Final region mask #######\n",
    "8. make new region file, last time check the position and the size\n",
    "## crosscheck with eckert ##\n",
    "9. edit the emllist.fits, *-bkgregtdet/sky.fits \n",
    "10. rerun the masks\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define homepath\n",
    "# homepath = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/data/RGH80/reduction'\n",
    "# homepath = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/data/ID9647/reduction'\n",
    "# homepath = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/data/ID828/reduction'\n",
    "# homepath = '/Users/eusracenorth/Documents/work/XGAP-ABUN/data/ID3460/reduction/SDSSTG3460'\n",
    "os.chdir(f'{homepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 Exclude chips in the events\n",
    "check set_chips_on.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG4936')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        # Read the content from the text file\n",
    "        with open(\"set_chips_on.txt\", \"r\") as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Extract values from the content\n",
    "        m1on_values = content.split('\"')[1].split()\n",
    "        m2on_values = content.split('\"')[3].split()\n",
    "\n",
    "        # Find the indices where values are 'F' for M1ON and M2ON\n",
    "        mos1_f_indices = [i + 1 for i, value in enumerate(m1on_values) if value == \"F\"]\n",
    "        mos2_f_indices = [i + 1 for i, value in enumerate(m2on_values) if value == \"F\"]\n",
    "\n",
    "        #### !! NOTE: PN chips are always not excluded!\n",
    "        exchip_dir = {'mos1':mos1_f_indices, 'mos2':mos2_f_indices, 'pn':[]}\n",
    "        express = f'''filtertype=expression imagebinning='imageSize' imagedatatype='Int32' squarepixels=yes ignorelegallimits=yes withxranges=yes withyranges=yes xcolumn='X' ximagesize=900 ximagemax=48400 ximagemin=3401 ycolumn='Y' yimagesize=900 yimagemax=48400 yimagemin=3401 updateexposure=yes filterexposure=yes verbosity=4'''\n",
    "\n",
    "        f = open('exchip_inevt.sh', 'w')\n",
    "        name_dir = {'mos1':'mos1*-allevc', 'mos2':'mos2*-allevc', 'pn':'pn*-allevc'}\n",
    "        for name in ['mos1', 'mos2', 'pn']: # , 'mos2S002'\n",
    "            add_express = ''\n",
    "            input_evtfile = glob(f'{name_dir[name]}.fits')[0]\n",
    "            oot_evtfile = glob(f'pn*-allevcoot.fits')[0]\n",
    "            output_evtfile = f'{name}-allevc-exchips.fits'\n",
    "            output_imgfile = f'{name}-allevc-exchips_img.fits'\n",
    "            if len(exchip_dir[name]) > 0:\n",
    "                for chip in exchip_dir[name]:\n",
    "                    add_express += f'&&(CCDNR.ne.{chip})' \n",
    "                \n",
    "            if 'mos' in name:\n",
    "                f.write(f'''evselect table={input_evtfile}:EVENTS withfilteredset=yes filteredset={output_evtfile} expression=\"(#XMMEA_EM)&&(PATTERN<=12)&&((FLAG & 0x766aa000) == 0){add_express}\" {express} imageset={output_imgfile} \\n''')\n",
    "            else:\n",
    "                f.write(f'''evselect table={input_evtfile}:EVENTS withfilteredset=yes filteredset={output_evtfile} expression=\"(#XMMEA_EP)&&(PATTERN<=4)&&((FLAG & 0xb0000) == 0)&&((FLAG & 0x766aa000) == 0){add_express}\" {express} imageset={output_imgfile} \\n''')\n",
    "                f.write(f'''evselect table={oot_evtfile}:EVENTS withfilteredset=yes filteredset=pn-allevcoot-exchips.fits expression=\"(#XMMEA_EP)&&(PATTERN<=4)&&((FLAG & 0xb0000) == 0)&&((FLAG & 0x766aa000) == 0){add_express}\" {express} imageset={output_imgfile} \\n''')\n",
    "\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 extract as many point sources using cheese as possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        mos1evt = glob(f'mos1*allevc-exchips.fits')[0]\n",
    "        mos2evt = glob(f'mos2*allevc-exchips.fits')[0]\n",
    "        pnevt = glob(f'pn*allevc-exchips.fits')[0]\n",
    "        pnootevt = glob(f'pn*allevcoot-exchips.fits')[0]\n",
    "        f = open('cheese.sh', 'w')\n",
    "        f.write(f'''\n",
    "source set_sas.txt\n",
    "elo=350 \n",
    "ehi=2000\n",
    "cheese mos1file='{mos1evt}' mos2file='{mos2evt}' pnfile='{pnevt}' pnootfile='{pnootevt}' elowlist=$elo ehighlist=$ehi scale=0.5 mlmin=1 dist=1. ratetotal=3e-6 keepinterfiles=no 2>&1 | tee cheese_max.log\n",
    "        '''\n",
    "        )\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for homepath in homepaths:\n",
    "    os.chdir(homepath)\n",
    "    \n",
    "    # Check if there are any files matching the pattern *SUM.SAS\n",
    "    matching_files = glob('*SUM.SAS')\n",
    "\n",
    "    if matching_files:\n",
    "        f = open('emlfill.sh', 'w')\n",
    "        f.write(f'emlfill emlin=emllist.fits emlout=emllist_filled.fits')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 comb merge the mos1, mos2, pn images,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSS*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    os.chdir(homepath)\n",
    "    \n",
    "    # Check if there are any files matching the pattern *SUM.SAS\n",
    "    matching_files = glob('*SUM.SAS')\n",
    "\n",
    "    if matching_files:\n",
    "        f = open('comb_img.sh', 'w')\n",
    "\n",
    "        elo = 350\n",
    "        ehi = 2000\n",
    "\n",
    "        express = f'(PATTERN<=4)&&((FLAG & 0xb0000) == 0)&&((FLAG & 0x762a097c) == 0)&&(PI in [{elo}:{ehi}])&&(DETY in [-16510:14345])'\n",
    "        plot_express = f'''imagebinning='imageSize' imagedatatype='Int32' imageset=mos1S001-fovimt.fits squarepixels=yes ignorelegallimits=yes withxranges=yes withyranges=yes xcolumn='X' ximagesize=900 ximagemax=48400 ximagemin=3401 ycolumn='Y' yimagesize=900 yimagemax=48400 yimagemin=3401'''\n",
    "\n",
    "\n",
    "        f.write(f'''\n",
    "        source set_sas.txt\n",
    "        evselect table=pnS003-allevcoot-exchips.fits withimageset=Y {plot_express} expression='{express}' imageset='pnS003-fovimootsky-{elo}-{ehi}.fits'  \\n''')\n",
    "        for name in ['mos1S001', 'mos2S002', 'pnS003']:\n",
    "            f.write(f'mv {name}-fovimt.fits {name}-fovimsky-{elo}-{ehi}.fits\\n')\n",
    "            f.write(f'mv {name}-fovimtexp.fits {name}-expimsky-{elo}-{ehi}.fits\\n')\n",
    "        f.write(f'''combimage prefixlist='1S001 2S002 S003' withcheese=yes cheesetype=t elowlist={elo} ehighlist={ehi} 2>&1 | tee combimg.log\\n''')\n",
    "        f.write(f'''mv comb-fovimsky-{elo}-{ehi}.fits comb-fovimsky-{elo}-{ehi}_masked.fits\\n''')\n",
    "        f.write(f'''mv comb-expimsky-{elo}-{ehi}.fits comb-expimsky-{elo}-{ehi}_masked.fits\\n''')\n",
    "        f.write(f'''combimage prefixlist='1S001 2S002 S003' withcheese=no elowlist={elo} ehighlist={ehi} 2>&1 | tee -a combimg.log\\n''')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the emllist.fits to region file with fixed circle of 15â€œ\n",
    "from astropy.io import fits\n",
    "for homepath in homepaths:\n",
    "    os.chdir(homepath)\n",
    "    \n",
    "    # Check if there are any files matching the pattern *SUM.SAS\n",
    "    matching_files = glob('*SUM.SAS')\n",
    "\n",
    "    if matching_files and os.path.exists('emllist_filled.fits'):\n",
    "        with fits.open('emllist_filled.fits') as data_f:\n",
    "            data = data_f[1].data\n",
    "\n",
    "        f = open('emllist_filled.reg', 'w')\n",
    "        f.write('''fk5\\n''')\n",
    "\n",
    "        for i in range(len(data['ID_INST'])):\n",
    "            if data[i]['ID_INST']==0:\n",
    "                f.write(f'''circle({data[i]['RA']}, {data[i]['DEC']}, 15\")\\n''')\n",
    "        f.close()\n",
    "    else:\n",
    "        print(homepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.0 Blink check the emllist_filled with the comb image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 create the new bkgregtdet/sky.fits using region commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create emllist_every.fits, include all the possible point sources\n",
    "filename = f'emllist_filled.fits'\n",
    "os.system(f'cp {filename} emllist_every.fits')\n",
    "\n",
    "f = fits.open(filename)\n",
    "dat = f[1].data\n",
    "f.close()\n",
    "dat['FLAG'] = 0\n",
    "\n",
    "# load the styles of the recarray data \n",
    "sample_dype = dat.dtype\n",
    "sample = dat[0]\n",
    "\n",
    "# load the regions of complete pointsources\n",
    "srcname = f'emllist_every.reg'\n",
    "regfile = open(srcname)\n",
    "lines = regfile.readlines()\n",
    "regfile.close()\n",
    "\n",
    "num = len(lines)-3\n",
    "dat = dat[:num]\n",
    "\n",
    "for i, f in enumerate(lines[3:]):\n",
    "    ra = f.split('(')[-1].split(',')[0]\n",
    "    dec = f.split(',')[1]\n",
    "    dat[i]['RA'] = ra\n",
    "    dat[i]['DEC'] = dec\n",
    "    dat[i]['ML_ID_SRC'] = int(i+1)\n",
    "    dat[i]['DIST_NN'] = 1000\n",
    "    dat[i]['DET_ML'] = 20\n",
    "    dat[i]['BOX_ID_SRC'] = int(i+1)\n",
    "    dat[i]['ID_INST'] = 0\n",
    "    dat[i]['ID_BAND'] = 0\n",
    "    dat[i]['ID_CLUSTER'] = int(i+1)\n",
    "\n",
    "\n",
    "\n",
    "newf = fits.open(f'emllist_every.fits', mode='update')\n",
    "newf['SRCLIST'].data = dat\n",
    "newf.flush()\n",
    "newf.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 1st run of region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## if the SCTS is NULL in emllist_every.fits, the makemask won't work properly\n",
    "# ## UPDATE: SCTS can't solve the problem!\n",
    "f = fits.open('emllist_every.fits')\n",
    "dat = f[1].data\n",
    "for i in range(len(dat)):\n",
    "    if ~np.isfinite(dat[i]['SCTS']):\n",
    "        dat[i]['SCTS'] = 300\n",
    "\n",
    "os.system('cp emllist_every.fits emllist_every_filled.fits')\n",
    "newf = fits.open('emllist_every_filled.fits', mode='update')\n",
    "newf[1].data = dat\n",
    "newf.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## edit region files\n",
    "f = open(f'makemask_1st.sh', 'w')\n",
    "\n",
    "f.write(\n",
    "'''\n",
    "source set_sas.txt\n",
    "export M1=mos1S001\n",
    "export M2=mos2S002\n",
    "export PN=pnS003\n",
    "export elo=350\n",
    "export ehi=2000\n",
    "\n",
    "mkdir cheese_old\n",
    "for name in $M1 $M2 $PN\n",
    "do\n",
    "mv ${name}-cheeset.fits cheese_old\n",
    "mv ${name}-bkgregtdet.fits cheese_old\n",
    "mv ${name}-bkgregtsky.fits cheese_old\n",
    "\n",
    "region eventset=${name}-allevc-exchips.fits srclisttab=emllist_every_filled.fits:SRCLIST operationstyle=batch bkgfraction=0.1 radiusstyle=contour srcidcol=ML_ID_SRC shrinkconfused=no nosrcellipse=no nobkgellipse=no fovbkgannulus=no outunit=xy verbosity=4 regionset=sources_${name}_sky_srcreg.fits bkgregionset=sources_${name}_sky_bkgreg.fits | tee region-sky-${name}_2nd.log\n",
    "region eventset=${name}-allevc-exchips.fits srclisttab=emllist_every_filled.fits:SRCLIST operationstyle=batch bkgfraction=0.1 radiusstyle=contour srcidcol=ML_ID_SRC shrinkconfused=no nosrcellipse=no nobkgellipse=no fovbkgannulus=no outunit=detxy verbosity=4 regionset=sources_${name}_det_srcreg.fits bkgregionset=sources_${name}_det_bkgreg.fits | tee region-det-${name}_2nd.log\n",
    "\n",
    "# makemask imagefile=${name}-fovimsky-$elo-$ehi.fits maskfile=${name}-fovimtmask.fits regionfile=${name}-bkgregtsky.fits cheesefile=${name}-cheeset.fits 2>&1 | tee makemask-${name}_1st.log\n",
    "done\n",
    "\n",
    "'''\n",
    ")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the *bkgregtsky.fits to region file\n",
    "# the physical coordinates in mos1S001,mos2S002,pnS003-bkgregtsky should be the same\n",
    "\n",
    "f = open('sources_every_srcreg_phy.reg','w')\n",
    "f.write('physical\\n')\n",
    "\n",
    "data_f = fits.open('sources_mos1S001_sky_srcreg.fits')\n",
    "\n",
    "for i in range(1, len(data_f)):\n",
    "    dat = data_f[i].data\n",
    "    if np.isfinite(dat['R'][0][0]) & (dat['R'][0][0]>0):\n",
    "        f.write(f'''ellipse({dat['X'][0][0]},{dat['Y'][0][0]},{dat['R'][0][0]},{dat['R'][0][1]},{dat['ROTANG'][0][0]})\\n''')\n",
    "    else:\n",
    "        f.write(f'''ellipse({dat['X'][0][0]},{dat['Y'][0][0]},200,200,0)\\n''')     \n",
    "\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the *bkgregtsky.fits to region file\n",
    "# the physical coordinates in mos1S001,mos2S002,pnS003-bkgregtsky should be the same\n",
    "\n",
    "f = open('sources_every_bkgreg_phy.reg','w')\n",
    "f.write('physical\\n')\n",
    "\n",
    "data_f = fits.open('sources_mos1S001_sky_bkgreg.fits')\n",
    "\n",
    "for i in range(1,len(data_f)) :\n",
    "    dat = data_f[i].data\n",
    "    if len(dat) > 1:\n",
    "        if np.isfinite(dat[0]['R'][0]) & (dat['R'][0][0]>0):\n",
    "            f.write(f'''annulus({dat[0]['X'][0]},{dat[0]['Y'][0]},{dat[0]['R'][0]},{dat[0]['R'][1]})\\n''')\n",
    "        else:\n",
    "            f.write(f'''annulus({dat[0]['X'][0]},{dat[0]['Y'][0]},600,600)\\n''')     \n",
    "        for j in range(1, len(dat)):\n",
    "            if np.isfinite(dat[j]['R'][0]) & (dat['R'][0][0]>0):\n",
    "                f.write(f'''-ellipse({dat[j]['X'][0]},{dat[j]['Y'][0]},{dat[j]['R'][0]},{dat[j]['R'][1]},{dat[j]['ROTANG'][0]})\\n''')\n",
    "            else:\n",
    "                f.write(f'''-ellipse({dat[j]['X'][0]},{dat[j]['Y'][0]},250,250,0)\\n''')\n",
    "    else:\n",
    "        f.write(f'''annulus({dat[0]['X'][0]},{dat[0]['Y'][0]},250,800)\\n''')\n",
    "        f.write(f'''-ellipse({dat[0]['X'][0]},{dat[0]['Y'][0]},250,250,0)\\n''')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 check, resize some point sources regions, \n",
    "NOTE: and save to fk5 and physical coords \n",
    "(phy coords are the same for every inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the edited regions to individual small region\n",
    "## for srcreg\n",
    "f = open('sources_every_srcreg_phy.reg')\n",
    "lines = f.readlines()[1:]\n",
    "f.close()\n",
    "\n",
    "os.makedirs('srcs_regions', exist_ok=True)\n",
    "\n",
    "for i, l in enumerate(lines):\n",
    "    newf = open(f'srcs_regions/src_{int(i+1)}.reg', 'w')\n",
    "    newf.write(f'&&((X,Y) IN {l.strip()})')\n",
    "    newf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for bkgreg\n",
    "f = open('sources_every_bkgreg_phy.reg')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "os.makedirs('srcs_regions', exist_ok=True)\n",
    "i = 0\n",
    "\n",
    "for l in enumerate(lines[1:]):\n",
    "    if 'annu' in l[1]: \n",
    "        newf.close()\n",
    "        i+=1\n",
    "        newf = open(f'srcs_regions/bkg_{int(i)}.reg', 'w')\n",
    "        newf.write(f'&&((X,Y) IN {l[1].strip()})')\n",
    "    elif 'ellip' in l[1]:\n",
    "        newf.write(f'&&!((X,Y) IN {l[1][1:].strip()})')\n",
    "\n",
    "newf.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 inspect sources_every_src/bkgreg_phy.reg!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 extract spectra from source and bkg regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumf = open('sources_spec.sh', 'w')\n",
    "\n",
    "for name in ['mos1S001', 'mos2S002', 'pnS003']:\n",
    "    regdir = f'srcs_regions'\n",
    "    regs = glob(f'{regdir}/src_*.reg')\n",
    "    \n",
    "    f = open(f'src_spec_{name}.sh', 'w')\n",
    "    for reg in regs:\n",
    "\n",
    "        sf = open(reg)\n",
    "        regtxt = sf.readlines()[0]\n",
    "        sf.close()\n",
    "\n",
    "        if 'mos' in name:\n",
    "            f.write(f'\\n')\n",
    "            f.write(f'evselect table={name}-allevc-exchips.fits xcolumn=X ycolumn=Y imagebinning=binSize ximagebinsize=80 yimagebinsize=80 withimageset=Y imageset={reg.split(\".\")[0]}_{name}_img.fits withspectrumset=Y spectrumset={reg.split(\".\")[0]}_{name}_spec.pi energycolumn=PI spectralbinsize=5 withspecranges=yes specchannelmin=0 specchannelmax=11999 expression=\"(FLAG==0) && (PATTERN<=12) {regtxt}\"  | tee {reg.split(\".\")[0]}_{name}_spec.log\\n')\n",
    "        else:\n",
    "            f.write(f'\\n')\n",
    "            f.write(f'evselect table={name}-allevc-exchips.fits xcolumn=X ycolumn=Y imagebinning=binSize ximagebinsize=80 yimagebinsize=80 withimageset=Y imageset={reg.split(\".\")[0]}_{name}_img.fits withspectrumset=Y spectrumset={reg.split(\".\")[0]}_{name}_spec.pi energycolumn=PI spectralbinsize=5 withspecranges=yes specchannelmin=0 specchannelmax=20479 expression=\"(FLAG==0) && (PATTERN<=4) {regtxt}\"  | tee {reg.split(\".\")[0]}_{name}_spec.log\\n')\n",
    "    f.close()\n",
    "    sumf.write(f'''sh src_spec_{name}.sh\\n''')\n",
    "    \n",
    "\n",
    "sumf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumf = open('sources_bkg_spec.sh', 'w')\n",
    "\n",
    "for name in ['mos1S001', 'mos2S002', 'pnS003']:\n",
    "    regdir = f'srcs_regions'\n",
    "    regs = glob(f'{regdir}/bkg*.reg')\n",
    "    \n",
    "    f = open(f'bkg_spec_{name}.sh', 'w')\n",
    "    for reg in regs:\n",
    "\n",
    "        sf = open(reg)\n",
    "        regtxt = sf.readlines()[0]\n",
    "        sf.close()\n",
    "\n",
    "        if 'mos' in name:\n",
    "            f.write(f'\\n')\n",
    "            f.write(f'evselect table={name}-allevc-exchips.fits xcolumn=X ycolumn=Y imagebinning=binSize ximagebinsize=80 yimagebinsize=80 withimageset=Y imageset={reg.split(\".\")[0]}_{name}_img.fits withspectrumset=Y spectrumset={reg.split(\".\")[0]}_{name}_spec.pi energycolumn=PI spectralbinsize=5 withspecranges=yes specchannelmin=0 specchannelmax=11999 expression=\"(FLAG==0) && (PATTERN<=12) {regtxt}\"  | tee {reg.split(\".\")[0]}_{name}_spec.log\\n')\n",
    "        else:\n",
    "            f.write(f'\\n')\n",
    "            f.write(f'evselect table={name}-allevc-exchips.fits xcolumn=X ycolumn=Y imagebinning=binSize ximagebinsize=80 yimagebinsize=80 withimageset=Y imageset={reg.split(\".\")[0]}_{name}_img.fits withspectrumset=Y spectrumset={reg.split(\".\")[0]}_{name}_spec.pi energycolumn=PI spectralbinsize=5 withspecranges=yes specchannelmin=0 specchannelmax=20479 expression=\"(FLAG==0) && (PATTERN<=4) {regtxt}\"  | tee {reg.split(\".\")[0]}_{name}_spec.log\\n')\n",
    "    f.close()\n",
    "    sumf.write(f'''sh bkg_spec_{name}.sh\\n''')\n",
    "    \n",
    "sumf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 determine the cutoff flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 cal pointsource region area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create separate region file in fk5\n",
    "## 1. open sources_every_bkgreg_phy.reg\tsources_every_srcreg_phy.reg in ds9 and convert phy to fk5\n",
    "## 2. separate the sources*fk5.reg file to individual files \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(f'{homepath}')\n",
    "# separate the edited regions to individual small region\n",
    "## for srcreg\n",
    "f = open('sources_every_srcreg_fk5.reg')\n",
    "lines = f.readlines()[3:]\n",
    "f.close()\n",
    "\n",
    "for i, l in enumerate(lines):\n",
    "    newf = open(f'srcs_regions/fk5_src_{int(i+1)}.reg', 'w')\n",
    "    newf.write(f'fk5\\n')\n",
    "    newf.write(f'{l.strip()}\\n')\n",
    "    newf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for bkgreg\n",
    "f = open('sources_every_bkgreg_fk5.reg')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for l in enumerate(lines[3:]):\n",
    "    if 'annu' in l[1]: \n",
    "        newf.close()\n",
    "        i+=1\n",
    "        newf = open(f'srcs_regions/fk5_bkg_{int(i)}.reg', 'w')\n",
    "        newf.write(f'fk5\\n')\n",
    "        newf.write(f'{l[1].strip()}\\n')\n",
    "    elif 'ellip' in l[1]:\n",
    "        newf.write(f'{l[1].strip()}\\n')\n",
    "\n",
    "newf.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create mask log\n",
    "import pandas as pd\n",
    "\n",
    "# f = open(f'{datapath}/cal_regionarea.sh', 'w')\n",
    "CDELT = 6.94E-04 * 60 # arcmin per pixel\n",
    "os.chdir(f'{homepath}/srcs_regions')\n",
    "\n",
    "srcfiles = glob('fk5_src*reg')\n",
    "num = len(srcfiles)\n",
    "newf = open('cal_areaxsec.sh', 'w')\n",
    "\n",
    "for name in ['mos1S001', 'mos2S002', 'pnS003']:\n",
    "\n",
    "    for i in range(1,num+1):\n",
    "        srcreg = f'fk5_src_{int(i)}.reg'\n",
    "        bkgreg = f'fk5_bkg_{int(i)}.reg'\n",
    "\n",
    "        # newf.write(f'rm {srcreg.split(\".\")[0]}_{name}_msk.fits\\n')\n",
    "        # newf.write(f'rm {bkgreg.split(\".\")[0]}_{name}_msk.fits\\n')\n",
    "        # newf.write(f'rm {srcreg.split(\".\")[0]}_{name}_msk_exp.fits\\n')\n",
    "        # newf.write(f'rm {bkgreg.split(\".\")[0]}_{name}_msk_exp.fits\\n')\n",
    "        # newf.write(f'rm {srcreg.split(\".\")[0]}_{name}_msk.log\\n')\n",
    "        # newf.write(f'rm {bkgreg.split(\".\")[0]}_{name}_msk.log\\n')\n",
    "        \n",
    "\n",
    "        newf.write(f'ftimgcalc {srcreg.split(\".\")[0]}_{name}_msk.fits \\'regfilter(\"{srcreg}\",A.P1,A.P2) ? (1):(0)\\' a=../{name}-expimsky-350-2000.fits clobber=yes\\n')\n",
    "        newf.write(f'ftimgcalc {bkgreg.split(\".\")[0]}_{name}_msk.fits \\'regfilter(\"{bkgreg}\",A.P1,A.P2) ? (1):(0)\\' a=../{name}-expimsky-350-2000.fits clobber=yes\\n')\n",
    "\n",
    "        newf.write(f'farith {srcreg.split(\".\")[0]}_{name}_msk.fits ../{name}-expimsky-350-2000.fits {srcreg.split(\".\")[0]}_{name}_msk_exp.fits \"*\"\\n')\n",
    "        newf.write(f'farith {bkgreg.split(\".\")[0]}_{name}_msk.fits ../{name}-expimsky-350-2000.fits {bkgreg.split(\".\")[0]}_{name}_msk_exp.fits \"*\"\\n')\n",
    "\n",
    "        newf.write(f'fimgstat {srcreg.split(\".\")[0]}_{name}_msk_exp.fits threshlo=I threshup=I > {srcreg.split(\".\")[0]}_{name}_msk.log\\n')\n",
    "        newf.write(f'fimgstat {bkgreg.split(\".\")[0]}_{name}_msk_exp.fits threshlo=I threshup=I > {bkgreg.split(\".\")[0]}_{name}_msk.log\\n')\n",
    "\n",
    "newf.close()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make area csv ###\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# f = open(f'{datapath}/cal_regionarea.sh', 'w')\n",
    "CDELT = 2.5 # arcsec per pixel\n",
    "# os.chdir('srcs_regions')\n",
    "\n",
    "srcfiles = glob('fk5_src*reg')\n",
    "num = len(srcfiles)\n",
    "print(num)\n",
    "\n",
    "for name in ['mos1S001', 'mos2S002', 'pnS003']:\n",
    "    dir = {}\n",
    "    dir['srcidx'] = np.arange(1,num+1)\n",
    "    dir['srcarea[pixel]'] = np.zeros(int(num))\n",
    "    dir['bkgarea[pixel]'] = np.zeros(int(num))\n",
    "\n",
    "    for i in range(1,num+1):\n",
    "        srcreg = f'fk5_src_{int(i)}.reg'\n",
    "        bkgreg = f'fk5_bkg_{int(i)}.reg'\n",
    "        \n",
    "        f = open(f'{srcreg.split(\".\")[0]}_{name}_msk.log')\n",
    "        lines = f.readlines()[:]\n",
    "        f.close()\n",
    "        for line in lines:\n",
    "            if 'sum' in line:\n",
    "                dir['srcarea[pixel]'][int(i-1)] = float(line.split('=')[-1])\n",
    "\n",
    "        f = open(f'{bkgreg.split(\".\")[0]}_{name}_msk.log')\n",
    "        lines = f.readlines()[:]\n",
    "        f.close()\n",
    "        for line in lines:\n",
    "            if 'sum' in line:\n",
    "                dir['bkgarea[pixel]'][int(i-1)] = float(line.split('=')[-1])\n",
    "\n",
    "    df = pd.DataFrame(dir)\n",
    "    df.to_csv(f'sources_areasxsec_{name}.csv', index=False)\n",
    "        # backexp=\"{bkgtxt}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gen rmf ###\n",
    "os.chdir(f'{homepath}/srcs_regions')\n",
    "\n",
    "f = open(f'gen_rmf.sh', 'w')\n",
    "\n",
    "specfiles = glob('src_1_*_spec.pi')\n",
    "\n",
    "for specfile in specfiles:\n",
    "    \n",
    "    if 'mos1' in specfile:\n",
    "        badpix_file = f'../mos1S001-fovimsky-350-8000.fits'\n",
    "    elif 'mos2' in specfile:\n",
    "        badpix_file = f'../mos2S002-fovimsky-350-8000.fits'\n",
    "    else:\n",
    "        badpix_file = f'../pnS003-fovimsky-350-8000.fits'\n",
    "\n",
    "    f.write(f'''\n",
    "rmfgen spectrumset={specfile} rmfset={specfile.split('.')[0]}.rmf detmaptype=flat extendedsource=yes badpixlocation={badpix_file}\\n\n",
    "        ''') \n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "# arfgen spectrumset=source_{inst}_{obs}_bkg_spec_bin5.fits {set3} rmfset=source_{inst}_{obs}_bkg.rmf arfset=source_{inst}_{obs}_bkg.arf badpixlocation={inst}_hiband_loband_clean_fov.fits\\n\n",
    "#     for reg in ['oofov']:#['reg1', 'reg2', 'reg3', 'reg4', 'reg5']:\n",
    "#         f.write(f'''\n",
    "# rmfgen spectrumset=source_{inst}_{obs}_{reg}_spec_bin.fits rmfset=source_{inst}_{obs}_{reg}.rmf detmaptype=flat extendedsource=yes badpixlocation={inst}_hiband_loband_clean_fov.fits\\n\n",
    "#         ''')# arfgen spectrumset=source_{inst}_{obs}_{reg}_spec.fits {set3} rmfset=source_{inst}_{obs}_{reg}.rmf arfset=source_{inst}_{obs}_{reg}.arf badpixlocation={inst}_hiband_loband_clean_fov.fits\\n\n",
    "\n",
    "# f = open(f'gen_arf_rmf_{obs}.sh')\n",
    "# print(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 determine the excluded point sources cutoff flux\n",
    "\n",
    "get counts rate from the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "CDELT = 6.94E-04  # deg\n",
    "\n",
    "regdir = f'{homepath}/srcs_regions'\n",
    "os.chdir(regdir)\n",
    "\n",
    "flux2cts = [4.907, 4.907, 13.55] # thin\n",
    "\n",
    "sens = [1.15e-6, 1.28e-6, 1.78e-6]\n",
    "xbreak_init = [4e-6, 3e-6, 7e-6]\n",
    "\n",
    "\n",
    "srcspec_set = glob('src_*_*_spec.pi')\n",
    "bkgspec_set = glob('bkg_*_*_spec.pi')\n",
    "num = len(glob('src_*_mos1S001_spec.pi'))\n",
    "print(num)\n",
    "\n",
    "\n",
    "\n",
    "def broken_power_law(x, a1, a2, b2, x_break):\n",
    "    b1=0\n",
    "    y = np.piecewise(x, [x < x_break, x >= x_break], [lambda x: a1 * x ** b1, lambda x: a2 * x ** b2])\n",
    "    return y\n",
    "\n",
    "totctr_dict = {}\n",
    "srcctr_dict = {}\n",
    "\n",
    "for j, name in enumerate(['mos1S001', 'mos2S002', 'pnS003']):\n",
    "    # read the s* arcmin2\n",
    "    df = pd.read_csv(f'sources_areasxsec_{name}.csv')\n",
    "    srcarea = df['srcarea[pixel]']\n",
    "    bkgarea = df['bkgarea[pixel]']\n",
    "\n",
    "    # # tranverse the channels to energies\n",
    "    # rmf_file = glob(f'*_{name}_*.rmf')\n",
    "    # f = fits.open(rmf_file[0])\n",
    "    # ch2en = f[2].data\n",
    "    # f.close()\n",
    "\n",
    "    # elo = ch2en['E_MIN']\n",
    "    # ehi = ch2en['E_MAX']\n",
    "    # ch = ch2en['CHANNEL']\n",
    "    # emsk = (elo < 8.0) & (elo >2.0)\n",
    "\n",
    "    src_cts = np.zeros(int(num))\n",
    "    bkg_cts = np.zeros(int(num))\n",
    "\n",
    "    for i in range(1, num+1):\n",
    "        srcspec = f'src_{i}_{name}_spec.pi'\n",
    "        bkgspec = f'bkg_{i}_{name}_spec.pi'\n",
    "        if (srcspec in srcspec_set) & (bkgspec in bkgspec_set):\n",
    "            f = fits.open(f'{srcspec}')\n",
    "            src_spec = f[1].data\n",
    "            src_cts[int(i-1)] = np.sum(src_spec['COUNTS'])\n",
    "\n",
    "            f = fits.open(f'{bkgspec}')\n",
    "            bkg_spec = f[1].data\n",
    "            bkg_cts[int(i-1)] = np.sum(bkg_spec['COUNTS'])\n",
    "        else:\n",
    "            src_cts[int(i-1)] = 0\n",
    "            bkg_cts[int(i-1)] = 0\n",
    "\n",
    "    print(src_cts)\n",
    "    print(bkg_cts)\n",
    "    srcctr = src_cts/(srcarea)\n",
    "    srcctr[~np.isfinite(srcctr)] = np.nan\n",
    "\n",
    "    bkgctr = bkg_cts/(bkgarea)\n",
    "    bkgctr[~np.isfinite(bkgctr)] = np.nan\n",
    "    print(srcctr)\n",
    "    print(bkgctr)\n",
    "####### make the plot #######\n",
    "    \n",
    "    fig = plt.subplots()\n",
    "    plt.title(f'{name}')\n",
    "    plt.xlabel(f'$S_{{2-8keV}}$ [cts/s/pixel]')\n",
    "    plt.ylabel('N')\n",
    "\n",
    "    plt.axvline(sens[j], c = 'k')\n",
    "    \n",
    "    totctr_dict[name] = srcctr-bkgctr\n",
    "    srcctr_dict[name] = srcctr\n",
    "\n",
    "    y, x = np.histogram(srcctr, bins = np.linspace(np.nanmin(srcctr), np.nanmax(srcctr), 10))\n",
    "\n",
    "    hist_y = np.cumsum(y[::-1])[::-1]\n",
    "    plt.stairs(hist_y, x)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    # plt.xlim(1e-3, 1)\n",
    "    # plt.ylim(0,20)\n",
    "\n",
    "\n",
    "    initial_guess = [1, 1, -0.1, xbreak_init[j]]  # a1, b1, a2, b2, x_break\n",
    "    parameter_bounds = ([0, 0, -np.inf, 0], [np.inf, np.inf, 0, 5e-5])\n",
    "\n",
    "    x_mid = x[0:-1] + np.diff(x)/2\n",
    "    params, covariance = curve_fit(broken_power_law, x_mid[:-1], hist_y[:-1], p0=initial_guess, bounds=parameter_bounds)\n",
    "    a1, a2, b2, x_break = params\n",
    "\n",
    "    print(params)\n",
    "    print(f'x_break_flux_to_mos = {x_break/flux2cts[j] * flux2cts[0]}')\n",
    "    y_fit = broken_power_law(x_mid, a1, a2, b2, x_break)\n",
    "    print(y_fit)\n",
    "    plt.plot(x_mid, y_fit)\n",
    "    # plt.hist(srcctr-bkgctr, bins = np.linspace(1e-7, 2e-5, 20))\n",
    "    # plt.xlim(1e-7, 2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 edit the emllist_final.fits\n",
    "1) throw away the point sources under the cutoff limit \n",
    "cutoff limit is 3.0e-6 cts/s/pixel in mos, 7e-6 in pn\n",
    "2) last adjust the size\n",
    "3) check the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 throw away the point sources under the cutoff limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(totctr_dict)\n",
    "# df[~np.isfinite(df)] = 0\n",
    "df['pnS003'] = df['pnS003']/13.55 * 4.907\n",
    "# ### not sub bkg:\n",
    "# df = pd.DataFrame(srcctr_dict)\n",
    "# df['pnS003'] = df['pnS003']/13.55 * 4.907\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4)) \n",
    "\n",
    "for name in ['mos1S001', 'mos2S002', 'pnS003']: # \n",
    "    if 'pn' in name:\n",
    "        axs[0].plot(np.arange(len(totctr_dict[name])), totctr_dict[name]/13.55 * 4.907, alpha = 0.5, label = name)\n",
    "    else:\n",
    "        axs[0].plot(np.arange(len(totctr_dict[name])), totctr_dict[name], alpha = 0.5, label = name)\n",
    "\n",
    "\n",
    "v = np.nanmax(df, axis=1)\n",
    "v1 = np.nansum(df, axis=1)\n",
    "axs[0].plot(np.arange(len(totctr_dict[name])), v, 'r--', label = 'max')\n",
    "axs[0].plot(np.arange(len(totctr_dict[name])), v1, 'b--', label = 'sum')\n",
    "\n",
    "axs[0].legend()\n",
    "\n",
    "\n",
    "print(df.iloc[0:9])\n",
    "hist, bin = np.histogram(v, bins = np.linspace(np.nanmin(v), np.nanmax(v), 10))\n",
    "axs[1].stairs(hist, bin, label = 'max', color ='r', linestyle = '--')\n",
    "axs[2].stairs(np.cumsum(hist[::-1])[::-1], bin, label = 'max', color ='r', linestyle = '--')\n",
    "hist, bin = np.histogram(v1, bins = np.linspace(np.nanmin(v), np.nanmax(v), 10))\n",
    "axs[1].stairs(hist, bin, label = 'sum', color = 'b')\n",
    "axs[2].stairs(np.cumsum(hist[::-1])[::-1], bin, label = 'sum', color ='b')\n",
    "\n",
    "axs[1].legend()\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].axvline(1.3e-5, c = 'r', linestyle = 'dashed')\n",
    "axs[0].axhline(1.3e-5, c = 'r', linestyle = 'dashed')\n",
    "axs[2].axvline(1.3e-5, c = 'r', linestyle = 'dashed')\n",
    "\n",
    "axs[1].axvline(1.3e-5, c = 'b')\n",
    "axs[0].axhline(1.3e-5, c = 'b')\n",
    "axs[2].axvline(1.3e-5, c = 'b')\n",
    "\n",
    "axs[1].set_title('hist')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_ylabel('N')\n",
    "axs[1].set_xlabel('S (bg subtracted) [cts/s/pixel]')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel('src idx')\n",
    "axs[0].set_ylabel('S (bg subtracted) [cts/s/pixel]')\n",
    "\n",
    "axs[2].set_title('logN-logS')\n",
    "axs[2].set_xscale('log')\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_ylabel('N')\n",
    "axs[2].set_xlabel('S (bg subtracted) [cts/s/pixel]')\n",
    "axs[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = v1>1.3e-5\n",
    "\n",
    "print(f'''Every sources: {len(v)}''')\n",
    "print(f'''Cut off point sources: {np.sum(~msk)}''')\n",
    "\n",
    "\n",
    "sel_idx = list(np.arange(len(v))[msk])\n",
    "os.chdir(homepath)\n",
    "\n",
    "f = open(f'sources_every_srcreg_fk5.reg')\n",
    "lines = f.readlines()[3:]\n",
    "f.close()\n",
    "\n",
    "newf = open(f'sources_final_sum_srcreg_fk5.reg', 'w')\n",
    "newf.write('fk5\\n')\n",
    "\n",
    "for i in range(len(sel_idx)):\n",
    "    newf.write(lines[sel_idx[i]])\n",
    "newf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 Last check the sum*final*reg! -> sum*final*edit.reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 2nd and last run of region command\n",
    "\n",
    "if consider region command in cheese, \n",
    "this is actually the 3rd time to run region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create emllist_final.fits, to convert the centers of fk5 coords to detxy and xy coords\n",
    "filename = f'emllist_final.fits'\n",
    "os.system(f'cp emllist.fits {filename}')\n",
    "\n",
    "f = fits.open(filename)\n",
    "dat = f[1].data\n",
    "f.close()\n",
    "dat['FLAG'] = 0\n",
    "\n",
    "# load the styles of the recarray data \n",
    "sample_dype = dat.dtype\n",
    "sample = dat[0]\n",
    "\n",
    "# load the regions of complete pointsources\n",
    "srcname = f'sources_final_sum_srcreg_fk5_edit.reg'\n",
    "regfile = open(srcname)\n",
    "lines = regfile.readlines()[:]\n",
    "regfile.close()\n",
    "\n",
    "num = len(lines)-3\n",
    "dat = dat[:num]\n",
    "\n",
    "for i, f in enumerate(lines[3:]):\n",
    "    if len(f) > 1:\n",
    "        ra = f.split('(')[-1].split(',')[0]\n",
    "        dec = f.split(',')[1]\n",
    "        dat[i]['RA'] = ra\n",
    "        dat[i]['DEC'] = dec\n",
    "        dat[i]['ML_ID_SRC'] = int(i+1)\n",
    "        dat[i]['DIST_NN'] = 1000\n",
    "        dat[i]['DET_ML'] = 20\n",
    "        dat[i]['BOX_ID_SRC'] = int(i+1)\n",
    "        dat[i]['ID_INST'] = 0\n",
    "        dat[i]['ID_BAND'] = 0\n",
    "        dat[i]['ID_CLUSTER'] = int(i+1)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "newf = fits.open(f'{filename}', mode='update')\n",
    "newf['SRCLIST'].data = dat\n",
    "newf.flush()\n",
    "newf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## edit region files\n",
    "\n",
    "os.makedirs('cheese_old', exist_ok=True)\n",
    "f = open(f'region_2nd.sh', 'w')\n",
    "\n",
    "f.write(\n",
    "'''\n",
    "source set_sas.txt\n",
    "export M1=mos1S001\n",
    "export M2=mos2S002\n",
    "export PN=pnS003\n",
    "export elo=350\n",
    "export ehi=8000\n",
    "\n",
    "for name in $M1 $M2 $PN\n",
    "do\n",
    "\n",
    "region eventset=${name}-allevc-exchips.fits operationstyle=global srclisttab=emllist_final.fits:SRCLIST expression=\"(ID_INST == 0)&&(DET_ML >= 1)\" bkgregionset=${name}-bkgregtdet.fits bkgfraction=0.1 radiusstyle=contour outunit=detxy verbosity=4 2>&1 | tee region-det-${name}_2nd.log\n",
    "region eventset=${name}-allevc-exchips.fits operationstyle=global srclisttab=emllist_final.fits:SRCLIST expression=\"(ID_INST == 0)&&(DET_ML >= 1)\" bkgregionset=${name}-bkgregtsky.fits bkgfraction=0.1 radiusstyle=contour outunit=xy verbosity=4 2>&1 | tee region-sky-${name}_2nd.log\n",
    "\n",
    "mv ${name}-bkgregtdet.fits ${name}-bkgregtdet_coords.fits\n",
    "mv ${name}-bkgregtsky.fits ${name}-bkgregtsky_coords.fits\n",
    "\n",
    "done\n",
    "\n",
    "'''\n",
    ")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alter the radius in *-bkgregtdet.fits and *-bkgregtsky.fits\n",
    "\n",
    "as2det = 20 # 1arcsec to detxy or xy\n",
    "\n",
    "for name in ['mos1S001', 'mos2S002', 'pnS003']:\n",
    "    fname_det = f'{name}-bkgregtdet_coords.fits'\n",
    "    fname_sky = f'{name}-bkgregtsky_coords.fits'\n",
    "    \n",
    "    for filename in [fname_det, fname_sky]:\n",
    "        os.system(f'''cp {filename} {filename.split('_')[0]}.fits''')\n",
    "\n",
    "        f = fits.open(filename)\n",
    "        dat = f[1].data\n",
    "        f.close()\n",
    "\n",
    "        # load the styles of the recarray data \n",
    "        sample_dype = dat.dtype\n",
    "        sample = dat[0]\n",
    "\n",
    "        # load the regions of complete pointsources\n",
    "        srcname = f'sources_final_sum_srcreg_fk5_edit.reg'\n",
    "        regfile = open(srcname)\n",
    "        lines = regfile.readlines()[:]\n",
    "        regfile.close()\n",
    "\n",
    "        num = len(lines)-3\n",
    "        dat = dat[:num]\n",
    "\n",
    "        for i, f in enumerate(lines[3:]):\n",
    "            if len(f) > 1:\n",
    "                if 'circle' in f:\n",
    "                    r = float(f.split(',')[-1][:-3]) * as2det\n",
    "                    dat[int(i)]['R'] = [r, r, 0, 0]\n",
    "                elif 'ellipse' in f:\n",
    "                    r2 = float(f.split(',')[-2][:-1]) * as2det\n",
    "                    r1 = float(f.split(',')[-3][:-1]) * as2det\n",
    "                    rot = float(f.split(',')[-1][:-2])\n",
    "                    dat[int(i)]['R'] = [r1, r2, 0, 0]\n",
    "                    dat[int(i)]['ROTANG'] = [rot, 0, 0, 0]\n",
    "\n",
    "                else:\n",
    "                    raise ValueError('Wrong shape, check the region file!')\n",
    "            else:\n",
    "                continue\n",
    "        newf = fits.open(f'''{filename.split('_')[0]}.fits''', mode='update')\n",
    "        newf['REGION'].data = dat\n",
    "        newf.flush()\n",
    "        newf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the *bkgregtsky.fits to region file\n",
    "# the physical coordinates in mos1S001,mos2S002,pnS003-bkgregtsky should be the same\n",
    "\n",
    "for name in ['mos1S001', 'mos2S002', 'pnS003']:\n",
    "    data_f = fits.open(f'{name}-bkgregtsky.fits')\n",
    "    dat = data_f[1].data\n",
    "\n",
    "    f = open(f'{name}-bkgregtsky.reg','w')\n",
    "    f.write('physical\\n')\n",
    "    for i in range(len(dat)):\n",
    "        f.write(f'''ellipse({dat[i]['X'][0]},{dat[i]['Y'][0]},{dat[i]['R'][0]},{dat[i]['R'][1]},{dat[i]['ROTANG'][0]})\\n''')\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.1 final check the regions! after that, make mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make mask!\n",
    "f = open(f'makemask_2nd.sh', 'w')\n",
    "for name in ['mos1S001', 'mos2S002', 'pnS003']:\n",
    "    f.write(f'''\n",
    "makemask imagefile={name}-fovimsky-350-2000.fits maskfile={name}-fovimtmask.fits regionfile={name}-bkgregtsky.fits cheesefile={name}-cheeset.fits 2>&1 | tee makemask-{name}_2nd.log\n",
    "    ''')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.2 check *-cheeset.fits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1302458d99d58fefb56dc0fec08d039cf240bdcae78a53a9226b7c46b3832fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
