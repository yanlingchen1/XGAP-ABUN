{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NOTE: \n",
    "This pipeline couldn't manage merged observations.\n",
    "Which would be developed in the near future.\n",
    "\n",
    "\n",
    "Steps:\n",
    "###### ensure point sources position and size ######\n",
    "#### position\n",
    "1. extract as many point sources using cheese as possible.\n",
    "1.1 emlfill\n",
    "2. comb merge the mos1, mos2, pn images,\n",
    "3. blink check the missing point sources, add or sub the point sources ra,dec\n",
    "#### size\n",
    "3.1 create the new bkgregtdet/sky.fits using region commands\n",
    "4. region and makemask command\n",
    "# check the result if all the point sources size and radec are nice!\n",
    "\n",
    "###### determine the cutoff flux or SB by logN-S #####\n",
    "5. divide the region file into individual files\n",
    "6. extract spectra from the region, make logN-logS plot\n",
    "7. determine the excluded point sources cutoff flux\n",
    "\n",
    "###### Final region mask #######\n",
    "8. make new region file, last time check the position and the size\n",
    "## crosscheck with eckert ##\n",
    "9. edit the emllist.fits, *-bkgregtdet/sky.fits \n",
    "10. rerun the masks\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define homepath\n",
    "# homepath = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/data/RGH80/reduction'\n",
    "# homepath = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/data/ID9647/reduction'\n",
    "# homepath = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/data/ID828/reduction'\n",
    "# homepath = '/Users/eusracenorth/Documents/work/XGAP-ABUN/data/ID3460/reduction/SDSSTG3460'\n",
    "os.chdir(f'{homepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Exclude chips in the events\n",
    "check set_chips_on.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG4936')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        # Read the content from the text file\n",
    "        with open(\"set_chips_on.txt\", \"r\") as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Extract values from the content\n",
    "        m1on_values = content.split('\"')[1].split()\n",
    "        m2on_values = content.split('\"')[3].split()\n",
    "\n",
    "        # Find the indices where values are 'F' for M1ON and M2ON\n",
    "        mos1_f_indices = [i + 1 for i, value in enumerate(m1on_values) if value == \"F\"]\n",
    "        mos2_f_indices = [i + 1 for i, value in enumerate(m2on_values) if value == \"F\"]\n",
    "\n",
    "        #### !! NOTE: PN chips are always not excluded!\n",
    "        exchip_dir = {'mos1':mos1_f_indices, 'mos2':mos2_f_indices, 'pn':[]}\n",
    "        express = f'''filtertype=expression imagebinning='imageSize' imagedatatype='Int32' squarepixels=yes ignorelegallimits=yes withxranges=yes withyranges=yes xcolumn='X' ximagesize=900 ximagemax=48400 ximagemin=3401 ycolumn='Y' yimagesize=900 yimagemax=48400 yimagemin=3401 updateexposure=yes filterexposure=yes verbosity=4'''\n",
    "\n",
    "        f = open('exchip_inevt.sh', 'w')\n",
    "        name_dir = {'mos1':'mos1*-allevc', 'mos2':'mos2*-allevc', 'pn':'pn*-allevc'}\n",
    "        for name in ['mos1', 'mos2', 'pn']: # , 'mos2S002'\n",
    "            add_express = ''\n",
    "            input_evtfile = glob(f'{name_dir[name]}.fits')[0]\n",
    "            oot_evtfile = glob(f'pn*-allevcoot.fits')[0]\n",
    "            output_evtfile = f'{name}-allevc-exchips.fits'\n",
    "            output_imgfile = f'{name}-allevc-exchips_img.fits'\n",
    "            if len(exchip_dir[name]) > 0:\n",
    "                for chip in exchip_dir[name]:\n",
    "                    add_express += f'&&(CCDNR.ne.{chip})' \n",
    "                \n",
    "            if 'mos' in name:\n",
    "                f.write(f'''evselect table={input_evtfile}:EVENTS withfilteredset=yes filteredset={output_evtfile} expression=\"(#XMMEA_EM)&&(PATTERN<=12)&&((FLAG & 0x766aa000) == 0){add_express}\" {express} imageset={output_imgfile} \\n''')\n",
    "            else:\n",
    "                f.write(f'''evselect table={input_evtfile}:EVENTS withfilteredset=yes filteredset={output_evtfile} expression=\"(#XMMEA_EP)&&(PATTERN<=4)&&((FLAG & 0xb0000) == 0)&&((FLAG & 0x766aa000) == 0){add_express}\" {express} imageset={output_imgfile} \\n''')\n",
    "                f.write(f'''evselect table={oot_evtfile}:EVENTS withfilteredset=yes filteredset=pn-allevcoot-exchips.fits expression=\"(#XMMEA_EP)&&(PATTERN<=4)&&((FLAG & 0xb0000) == 0)&&((FLAG & 0x766aa000) == 0){add_express}\" {express} imageset={name}-oot-allevc-exchips_img.fits \\n''')\n",
    "\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 extract as many point sources using cheese as possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        mos1evt = glob(f'mos1*allevc-exchips.fits')[0]\n",
    "        mos2evt = glob(f'mos2*allevc-exchips.fits')[0]\n",
    "        pnevt = glob(f'pn*allevc-exchips.fits')[0]\n",
    "        pnootevt = glob(f'pn*allevcoot-exchips.fits')[0]\n",
    "        f = open('cheese.sh', 'w')\n",
    "        f.write(f'''\n",
    "source set_sas.txt\n",
    "elo=350 \n",
    "ehi=2000\n",
    "cheese mos1file='{mos1evt}' mos2file='{mos2evt}' pnfile='{pnevt}' pnootfile='{pnootevt}' elowlist=$elo ehighlist=$ehi scale=0.5 mlmin=1 dist=1. ratetotal=3e-6 keepinterfiles=no 2>&1 | tee cheese_max.log\n",
    "        '''\n",
    "        )\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG2620')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        f = open('emlfill.sh', 'w')\n",
    "        f.write(f'emlfill emlin=emllist.fits emlout=emllist_filled.fits')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 comb merge the mos1, mos2, pn images,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        f = open('comb_img.sh', 'w')\n",
    "\n",
    "        elo = 350\n",
    "        ehi = 2000\n",
    "\n",
    "        name_dir = {'mos1':'mos1*-allevc', 'mos2':'mos2*-allevc', 'pn':'pn*-allevc'}\n",
    "\n",
    "        express = f'(PATTERN<=4)&&((FLAG & 0xb0000) == 0)&&((FLAG & 0x762a097c) == 0)&&(PI in [{elo}:{ehi}])&&(DETY in [-16510:14345])'\n",
    "        plot_express = f'''imagebinning='imageSize' imagedatatype='Int32' squarepixels=yes ignorelegallimits=yes withxranges=yes withyranges=yes xcolumn='X' ximagesize=900 ximagemax=48400 ximagemin=3401 ycolumn='Y' yimagesize=900 yimagemax=48400 yimagemin=3401'''\n",
    "\n",
    "        name_lst = []\n",
    "        prefix_lst = ''\n",
    "        for file in glob(f'*-cheeset.fits'):\n",
    "            prefix = file.split('-')[0]\n",
    "            name_lst.append(prefix)\n",
    "            if 'mos' in prefix:\n",
    "                prefix_lst += f\"{prefix[-5:]}  \"\n",
    "            else:\n",
    "                prefix_lst += f\"{prefix[-4:]}\"\n",
    "        for name in name_lst:\n",
    "            f.write(f'''source set_sas.txt \\n''')\n",
    "            f.write(f'''evselect table={name[0:-4]}-allevcoot-exchips.fits withimageset=Y {plot_express} expression='{express}' imageset='{name}-fovimootsky-{elo}-{ehi}.fits'  \\n''')\n",
    "            f.write(f'mv {name}-fovimt.fits {name}-fovimsky-{elo}-{ehi}.fits\\n')\n",
    "            f.write(f'mv {name}-fovimtexp.fits {name}-expimsky-{elo}-{ehi}.fits\\n')\n",
    "        f.write(f'''combimage prefixlist=\"{prefix_lst}\" withcheese=yes cheesetype=t elowlist={elo} ehighlist={ehi} 2>&1 | tee combimg.log\\n''')\n",
    "        f.write(f'''mv comb-fovimsky-{elo}-{ehi}.fits comb-fovimsky-{elo}-{ehi}_masked.fits\\n''')\n",
    "        f.write(f'''mv comb-expimsky-{elo}-{ehi}.fits comb-expimsky-{elo}-{ehi}_masked.fits\\n''')\n",
    "        f.write(f'''combimage prefixlist=\"{prefix_lst}\" withcheese=no elowlist={elo} ehighlist={ehi} 2>&1 | tee -a combimg.log\\n''')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the emllist.fits to region file with fixed circle of 15â€œ\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG2620')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "    \n",
    "        if os.path.exists('emllist_filled.fits'):\n",
    "            with fits.open('emllist_filled.fits') as data_f:\n",
    "                data = data_f[1].data\n",
    "\n",
    "            f = open('emllist_filled.reg', 'w')\n",
    "            f.write('''fk5\\n''')\n",
    "\n",
    "            for i in range(len(data['ID_INST'])):\n",
    "                if data[i]['ID_INST']==0:\n",
    "                    f.write(f'''circle({data[i]['RA']}, {data[i]['DEC']}, 15\")\\n''')\n",
    "            f.close()\n",
    "        else:\n",
    "            print(homepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 First check of pointsources regions, include as many 'likely' point sources as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.0 Blink check the emllist_filled with the comb image!\n",
    "and save to emllist_every.fits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "also need to exclude the cores. Just every suspicious pointsources!\n",
    "\n",
    "or the bkg regions later would be problematic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 create the new bkgregtdet/sky.fits using region commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create emllist_every.fits, include all the possible point sources\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('emllist_every.reg'):\n",
    "            filename = f'emllist_filled.fits'\n",
    "            os.system(f'cp {filename} emllist_every.fits')\n",
    "\n",
    "            f = fits.open(filename)\n",
    "            dat = f[1].data\n",
    "            f.close()\n",
    "            dat['FLAG'] = 0\n",
    "\n",
    "            # load the styles of the recarray data \n",
    "            sample_dype = dat.dtype\n",
    "            sample = dat[0]\n",
    "\n",
    "            # load the regions of complete pointsources\n",
    "            srcname = f'emllist_every.reg'\n",
    "            regfile = open(srcname)\n",
    "            lines = regfile.readlines()\n",
    "            regfile.close()\n",
    "\n",
    "            num = len(lines)-3\n",
    "            dat = dat[:num]\n",
    "\n",
    "            for i, f in enumerate(lines[3:]):\n",
    "                ra = f.split('(')[-1].split(',')[0]\n",
    "                dec = f.split(',')[1]\n",
    "                dat[i]['RA'] = ra\n",
    "                dat[i]['DEC'] = dec\n",
    "                dat[i]['ML_ID_SRC'] = int(i+1)\n",
    "                dat[i]['DIST_NN'] = 1000\n",
    "                dat[i]['DET_ML'] = 20\n",
    "                dat[i]['BOX_ID_SRC'] = int(i+1)\n",
    "                dat[i]['ID_INST'] = 0\n",
    "                dat[i]['ID_BAND'] = 0\n",
    "                dat[i]['ID_CLUSTER'] = int(i+1)\n",
    "\n",
    "\n",
    "\n",
    "            newf = fits.open(f'emllist_every.fits', mode='update')\n",
    "            newf['SRCLIST'].data = dat\n",
    "            newf.flush()\n",
    "            newf.close()\n",
    "        else:\n",
    "            print(homepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 1st run of region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## if the SCTS is NULL in emllist_every.fits, the makemask won't work properly\n",
    "# ## UPDATE: SCTS can't solve the problem!\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('emllist_every.reg'):\n",
    "            f = fits.open('emllist_every.fits')\n",
    "            dat = f[1].data\n",
    "            for i in range(len(dat)):\n",
    "                if ~np.isfinite(dat[i]['SCTS']):\n",
    "                    dat[i]['SCTS'] = 300\n",
    "\n",
    "            os.system('cp emllist_every.fits emllist_every_filled.fits')\n",
    "            newf = fits.open('emllist_every_filled.fits', mode='update')\n",
    "            newf[1].data = dat\n",
    "            newf.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## edit region files\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    # print(homepath)\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('emllist_every.reg'):\n",
    "            name_lst = []\n",
    "            for file in glob(f'*allevc-exchips.fits'):\n",
    "                prefix = file.split('-')[0]\n",
    "                name_lst.append(prefix)\n",
    "            \n",
    "            with open(f'makemask_1st.sh', 'w') as f:\n",
    "                f.write('''\n",
    "source set_sas.txt\n",
    "mkdir cheese_old\n",
    "elo=350\n",
    "ehi=2000\n",
    "''')\n",
    "                for prefix in name_lst:\n",
    "                    f.write(f'''\n",
    "\n",
    "mv {prefix}-cheeset.fits cheese_old\n",
    "mv {prefix}-bkgregtdet.fits cheese_old\n",
    "mv {prefix}-bkgregtsky.fits cheese_old\n",
    "\n",
    "region eventset={prefix}-allevc-exchips.fits srclisttab=emllist_every_filled.fits:SRCLIST operationstyle=batch bkgfraction=0.5 radiusstyle=contour srcidcol=ML_ID_SRC shrinkconfused=no nosrcellipse=no nobkgellipse=no fovbkgannulus=no outunit=xy verbosity=4 regionset=sources_{prefix}_sky_srcreg.fits bkgregionset=sources_{prefix}_sky_bkgreg.fits | tee region-sky-{prefix}_2nd.log\n",
    "region eventset={prefix}-allevc-exchips.fits srclisttab=emllist_every_filled.fits:SRCLIST operationstyle=batch bkgfraction=0.5 radiusstyle=contour srcidcol=ML_ID_SRC shrinkconfused=no nosrcellipse=no nobkgellipse=no fovbkgannulus=no outunit=detxy verbosity=4 regionset=sources_{prefix}_det_srcreg.fits bkgregionset=sources_{prefix}_det_bkgreg.fits | tee region-det-{prefix}_2nd.log\n",
    "                        ''')\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(homepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the *bkgregtsky.fits to region file\n",
    "# the physical coordinates in mos1S001,mos2S002,pnS003-bkgregtsky should be the same\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    # print(homepath)\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('sources_mos1_sky_srcreg.fits'):\n",
    "            f = open('sources_every_srcreg_phy.reg','w')\n",
    "            f.write('physical\\n')\n",
    "\n",
    "            data_f = fits.open('sources_mos1_sky_srcreg.fits')\n",
    "\n",
    "            for i in range(1, len(data_f)):\n",
    "                dat = data_f[i].data\n",
    "                if np.isfinite(dat['R'][0][0]) & (dat['R'][0][0]>0):\n",
    "                    f.write(f'''ellipse({dat['X'][0][0]},{dat['Y'][0][0]},{dat['R'][0][0]},{dat['R'][0][1]},{dat['ROTANG'][0][0]})\\n''')\n",
    "                else:\n",
    "                    f.write(f'''ellipse({dat['X'][0][0]},{dat['Y'][0][0]},200,200,0)\\n''')     \n",
    "\n",
    "            f.close()\n",
    "        else:\n",
    "            print(homepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the *bkgregtsky.fits to region file\n",
    "# the physical coordinates in mos1S001,mos2S002,pnS003-bkgregtsky should be the same\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    # print(homepath)\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('sources_mos1_sky_srcreg.fits'):\n",
    "            f = open('sources_every_bkgreg_phy.reg','w')\n",
    "            f.write('physical\\n')\n",
    "\n",
    "            data_f = fits.open('sources_mos1_sky_bkgreg.fits')\n",
    "\n",
    "            for i in range(1,len(data_f)) :\n",
    "                dat = data_f[i].data\n",
    "                if len(dat) > 1:\n",
    "                    if np.isfinite(dat[0]['R'][0]) & (dat['R'][0][0]>0):\n",
    "                        f.write(f'''annulus({dat[0]['X'][0]},{dat[0]['Y'][0]},{dat[0]['R'][0]},{dat[0]['R'][1]})\\n''')\n",
    "                    else:\n",
    "                        f.write(f'''annulus({dat[0]['X'][0]},{dat[0]['Y'][0]},600,600)\\n''')     \n",
    "                    for j in range(1, len(dat)):\n",
    "                        if np.isfinite(dat[j]['R'][0]) & (dat['R'][0][0]>0):\n",
    "                            f.write(f'''-ellipse({dat[j]['X'][0]},{dat[j]['Y'][0]},{dat[j]['R'][0]},{dat[j]['R'][1]},{dat[j]['ROTANG'][0]})\\n''')\n",
    "                        else:\n",
    "                            f.write(f'''-ellipse({dat[j]['X'][0]},{dat[j]['Y'][0]},250,250,0)\\n''')\n",
    "                else:\n",
    "                    f.write(f'''annulus({dat[0]['X'][0]},{dat[0]['Y'][0]},250,800)\\n''')\n",
    "                    f.write(f'''-ellipse({dat[0]['X'][0]},{dat[0]['Y'][0]},250,250,0)\\n''')\n",
    "            f.close()\n",
    "        else:\n",
    "            print(homepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 check, resize some point sources regions, \n",
    "NOTE: and save to fk5 and physical coords \n",
    "(phy coords are the same for every inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 inspect sources_every_src/bkgreg_phy.reg!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = f'/Users/eusracenorth/Downloads'\n",
    "rootdir = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP'\n",
    "# ids = ['12349', '3460', '828', '9647']\n",
    "with fits.open(f'{datapath}/xgap_m500_forecast.fits') as f:\n",
    "    dat = f[1].data\n",
    "    ids = dat['ID']\n",
    "# ids = ['4936', '9695']\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    subdir = f\"{rootdir}/SDSSTG{ids[i]}\"\n",
    "    savepath = f'{rootdir}/figs/srcs_every'\n",
    "    os.makedirs(savepath, exist_ok = True)\n",
    "    if os.path.exists(subdir):\n",
    "        os.chdir(subdir)\n",
    "        try:\n",
    "            os.system(f\"rm {savepath}/SDSSTG{ids[i]}.png\")\n",
    "            os.system(f'ds9 comb-fovimsky-350-2000.fits -region sources_every_srcreg_phy.reg -scale log -cmap b -smooth yes -colorbar no -zoom to fit &')\n",
    "            os.system(f'sleep 5')\n",
    "            os.system(f\"xpaset -p ds9 saveimage png {savepath}/SDSSTG{ids[i]}.png\")\n",
    "            os.system(f\"xpaset -p ds9 exit\")\n",
    "\n",
    "        except:\n",
    "            print(subdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 separate the regions to small regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the edited regions to individual small region\n",
    "## for srcreg\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    # print(homepath)\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('sources_mos1_sky_srcreg.fits'):\n",
    "            f = open('sources_every_srcreg_phy.reg')\n",
    "            lines = f.readlines()[1:]\n",
    "            f.close()\n",
    "\n",
    "            os.makedirs('srcs_regions', exist_ok=True)\n",
    "\n",
    "            for i, l in enumerate(lines):\n",
    "                newf = open(f'srcs_regions/src_{int(i+1)}.reg', 'w')\n",
    "                newf.write(f'&&((X,Y) IN {l.strip()})')\n",
    "                newf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for bkgreg\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    # print(homepath)\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('sources_mos1_sky_srcreg.fits'):\n",
    "            f = open('sources_every_bkgreg_phy.reg')\n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "\n",
    "            os.makedirs('srcs_regions', exist_ok=True)\n",
    "            i = 0\n",
    "\n",
    "            for l in enumerate(lines[1:]):\n",
    "                if 'annu' in l[1]: \n",
    "                    newf.close()\n",
    "                    i+=1\n",
    "                    newf = open(f'srcs_regions/bkg_{int(i)}.reg', 'w')\n",
    "                    newf.write(f'&&((X,Y) IN {l[1].strip()})')\n",
    "                elif 'ellip' in l[1]:\n",
    "                    newf.write(f'&&!((X,Y) IN {l[1][1:].strip()})')\n",
    "\n",
    "            newf.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 extract spectra from source and bkg regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    # print(homepath)\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('sources_every_bkgreg_phy.reg'):\n",
    "            sumf = open('sources_spec.sh', 'w')\n",
    "\n",
    "            for name in ['mos1', 'mos2', 'pn']:\n",
    "                regdir = f'srcs_regions'\n",
    "                regs = glob(f'{regdir}/src_*.reg')\n",
    "                \n",
    "                f = open(f'src_spec_{name}.sh', 'w')\n",
    "                for reg in regs:\n",
    "\n",
    "                    sf = open(reg)\n",
    "                    regtxt = sf.readlines()[0]\n",
    "                    sf.close()\n",
    "\n",
    "                    if 'mos' in name:\n",
    "                        f.write(f'\\n')\n",
    "                        f.write(f'evselect table={name}-allevc-exchips.fits xcolumn=X ycolumn=Y imagebinning=binSize ximagebinsize=80 yimagebinsize=80 withimageset=Y imageset={reg.split(\".\")[0]}_{name}_img.fits withspectrumset=Y spectrumset={reg.split(\".\")[0]}_{name}_spec.pi energycolumn=PI spectralbinsize=5 withspecranges=yes specchannelmin=0 specchannelmax=11999 expression=\"(FLAG==0) && (PATTERN<=12) {regtxt}\"  | tee {reg.split(\".\")[0]}_{name}_spec.log\\n')\n",
    "                    else:\n",
    "                        f.write(f'\\n')\n",
    "                        f.write(f'evselect table={name}-allevc-exchips.fits xcolumn=X ycolumn=Y imagebinning=binSize ximagebinsize=80 yimagebinsize=80 withimageset=Y imageset={reg.split(\".\")[0]}_{name}_img.fits withspectrumset=Y spectrumset={reg.split(\".\")[0]}_{name}_spec.pi energycolumn=PI spectralbinsize=5 withspecranges=yes specchannelmin=0 specchannelmax=20479 expression=\"(FLAG==0) && (PATTERN<=4) {regtxt}\"  | tee {reg.split(\".\")[0]}_{name}_spec.log\\n')\n",
    "                f.close()\n",
    "                sumf.write(f'''sh src_spec_{name}.sh\\n''')\n",
    "                \n",
    "\n",
    "            sumf.close()\n",
    "\n",
    "        else:\n",
    "            print(homepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    # print(homepath)\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('sources_every_bkgreg_phy.reg'):\n",
    "\n",
    "            sumf = open('sources_bkg_spec.sh', 'w')\n",
    "\n",
    "            for name in ['mos1', 'mos2', 'pn']:\n",
    "                regdir = f'srcs_regions'\n",
    "                regs = glob(f'{regdir}/bkg*.reg')\n",
    "                \n",
    "                f = open(f'bkg_spec_{name}.sh', 'w')\n",
    "                for reg in regs:\n",
    "\n",
    "                    sf = open(reg)\n",
    "                    regtxt = sf.readlines()[0]\n",
    "                    sf.close()\n",
    "\n",
    "                    if 'mos' in name:\n",
    "                        f.write(f'\\n')\n",
    "                        f.write(f'evselect table={name}-allevc-exchips.fits xcolumn=X ycolumn=Y imagebinning=binSize ximagebinsize=80 yimagebinsize=80 withimageset=Y imageset={reg.split(\".\")[0]}_{name}_img.fits withspectrumset=Y spectrumset={reg.split(\".\")[0]}_{name}_spec.pi energycolumn=PI spectralbinsize=5 withspecranges=yes specchannelmin=0 specchannelmax=11999 expression=\"(FLAG==0) && (PATTERN<=12) {regtxt}\"  | tee {reg.split(\".\")[0]}_{name}_spec.log\\n')\n",
    "                    else:\n",
    "                        f.write(f'\\n')\n",
    "                        f.write(f'evselect table={name}-allevc-exchips.fits xcolumn=X ycolumn=Y imagebinning=binSize ximagebinsize=80 yimagebinsize=80 withimageset=Y imageset={reg.split(\".\")[0]}_{name}_img.fits withspectrumset=Y spectrumset={reg.split(\".\")[0]}_{name}_spec.pi energycolumn=PI spectralbinsize=5 withspecranges=yes specchannelmin=0 specchannelmax=20479 expression=\"(FLAG==0) && (PATTERN<=4) {regtxt}\"  | tee {reg.split(\".\")[0]}_{name}_spec.log\\n')\n",
    "                f.close()\n",
    "                sumf.write(f'''sh bkg_spec_{name}.sh\\n''')\n",
    "                \n",
    "            sumf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 determine the cutoff flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 cal pointsource region area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create separate region file in fk5\n",
    "## 1. open sources_every_bkgreg_phy.reg\tsources_every_srcreg_phy.reg on mos1-allevc-exchips_img.fits in ds9 and convert phy to fk5\n",
    "## 2. separate the sources*fk5.reg file to individual files \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1.1 open sources_every_bkgreg_phy.reg\tsources_every_srcreg_phy.reg in ds9 and convert phy to fk5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOTE: Never run src regs and bkg regs together!!! #### \n",
    "\n",
    "\n",
    "import os\n",
    "from astropy.io import fits\n",
    "\n",
    "# datapath = '/Users/eusracenorth/Downloads'\n",
    "# with fits.open(f'{datapath}/xgap_m500_forecast.fits') as f:\n",
    "#     dat = f[1].data\n",
    "#     ids = dat['ID']\n",
    "\n",
    "rootdir = '/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP'\n",
    "ids = ['21128']\n",
    "for i in range(len(ids)):\n",
    "    subdir = f\"{rootdir}/SDSSTG{ids[i]}\"\n",
    "    savepath = f'{rootdir}/figs/srcs_every_phy'\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    if os.path.exists(subdir):\n",
    "        os.chdir(subdir)\n",
    "        \n",
    "        ##### src regs ######\n",
    "        os.system(f'rm sources_every_srcreg_fk5.reg')\n",
    "        os.system(f'rm {savepath}/SDSSTG{ids[i]}_srcreg.png')\n",
    "        os.system(f'ds9 mos2-allevc-exchips_img.fits -region sources_every_srcreg_phy.reg -scale log -cmap b -smooth yes -colorbar no -zoom to fit &')\n",
    "        os.system('sleep 5')\n",
    "        os.system(f\"xpaset -p ds9 regions system wcs\")\n",
    "        os.system(f\"xpaset -p ds9 regions sky fk5\")\n",
    "        os.system(f\"xpaset -p ds9 regions skyformat degrees\")\n",
    "        os.system(f\"xpaset -p ds9 regions save sources_every_srcreg_fk5.reg\")\n",
    "        os.system(f\"xpaset -p ds9 saveimage png {savepath}/SDSSTG{ids[i]}_srcreg.png\")\n",
    "        os.system(\"xpaset -p ds9 exit\")\n",
    "\n",
    "        # ###### bkg regs #########\n",
    "        # os.system(f'rm sources_every_bkgreg_fk5.reg')\n",
    "        # os.system(f'rm {savepath}/SDSSTG{ids[i]}_bkgreg.png')\n",
    "        # os.system(f'ds9 mos2-allevc-exchips_img.fits -region sources_every_BKGreg_phy.reg -scale log -cmap b -smooth yes -colorbar no -zoom to fit &')\n",
    "        # os.system('sleep 5')\n",
    "        # os.system(f\"xpaset -p ds9 regions system wcs\")\n",
    "        # os.system(f\"xpaset -p ds9 regions sky fk5\")\n",
    "        # os.system(f\"xpaset -p ds9 regions skyformat degrees\")\n",
    "        # os.system(f\"xpaset -p ds9 regions save sources_every_bkgreg_fk5.reg\")\n",
    "        # os.system(f\"xpaset -p ds9 saveimage png {savepath}/SDSSTG{ids[i]}_bkgreg.png\")\n",
    "        # os.system(\"xpaset -p ds9 exit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG3128')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('sources_every_srcreg_fk5.reg'):\n",
    "\n",
    "            os.chdir(f'{homepath}')\n",
    "            # separate the edited regions to individual small region\n",
    "            ## for srcreg\n",
    "            f = open('sources_every_srcreg_fk5.reg')\n",
    "            lines = f.readlines()[3:]\n",
    "            \n",
    "            if len(lines)>100:\n",
    "                print(homepath)\n",
    "                print(len(lines))\n",
    "            f.close()\n",
    "\n",
    "            for i, l in enumerate(lines):\n",
    "                newf = open(f'srcs_regions/fk5_src_{int(i+1)}.reg', 'w')\n",
    "                newf.write(f'fk5\\n')\n",
    "                newf.write(f'{l.strip()}\\n')\n",
    "                newf.close()\n",
    "\n",
    "        else:\n",
    "            print(homepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG3128')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('sources_every_bkgreg_fk5.reg'):\n",
    "\n",
    "            os.chdir(f'{homepath}')\n",
    "            ## for bkgreg\n",
    "            f = open('sources_every_bkgreg_fk5.reg')\n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "            if len(lines)>300:\n",
    "                print(homepath)\n",
    "                print(len(lines))\n",
    "            i = 0\n",
    "\n",
    "            for l in enumerate(lines[3:]):\n",
    "                if 'annu' in l[1]: \n",
    "                    newf.close()\n",
    "                    i+=1\n",
    "                    newf = open(f'srcs_regions/fk5_bkg_{int(i)}.reg', 'w')\n",
    "                    newf.write(f'fk5\\n')\n",
    "                    newf.write(f'{l[1].strip()}\\n')\n",
    "                elif 'ellip' in l[1]:\n",
    "                    newf.write(f'{l[1].strip()}\\n')\n",
    "            # newf.close()\n",
    "        else:\n",
    "            print(homepath)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1.2 check if sources_every_*reg_fky.reg exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_directories_without_file(root_directory, target_file):\n",
    "    missing_directories = []\n",
    "\n",
    "    for subdir in os.listdir(root_directory):\n",
    "        subdirectory_path = os.path.join(root_directory, subdir)\n",
    "        file_path = os.path.join(subdirectory_path, target_file)\n",
    "\n",
    "        if os.path.isdir(subdirectory_path) and not os.path.exists(file_path):\n",
    "            missing_directories.append(subdirectory_path)\n",
    "\n",
    "    return missing_directories\n",
    "\n",
    "root_directory = rootdir\n",
    "target_file = \"sources_every_bkgreg_fk5.reg\"\n",
    "\n",
    "missing_directories = find_directories_without_file(root_directory, target_file)\n",
    "\n",
    "if missing_directories:\n",
    "    print(\"Subdirectories without the file:\")\n",
    "    lst = []\n",
    "    for directory in missing_directories:\n",
    "        if 'TG' in directory:\n",
    "            lst.append(directory.split('TG')[-1])\n",
    "            \n",
    "else:\n",
    "    print(\"All subdirectories have the file.\")\n",
    "print(lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1.3 check if sources_every_*reg_fk5.reg has content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "srclst = []\n",
    "bkglst = []\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        if os.path.exists('sources_every_srcreg_fk5.reg'):\n",
    "            ## for bkgreg\n",
    "            f = open('sources_every_bkgreg_fk5.reg')\n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "            bkg_num = len(lines)\n",
    "            f = open('sources_every_srcreg_fk5.reg')\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            src_num = len(lines)\n",
    "\n",
    "            if (src_num<5):\n",
    "                srclst.append(homepath.split('TG')[-1])\n",
    "                print('src')\n",
    "                print(homepath)\n",
    "            if (bkg_num<5):\n",
    "                bkglst.append(homepath.split('TG')[-1])\n",
    "                print('bkg')\n",
    "                print(homepath)\n",
    "        else: print(f'{homepath} do not have sources*every*fk5.reg !')\n",
    "print(f'src: {lst}')\n",
    "print(f'bkg: {lst}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_for_string_in_file(root_directory, target_file, search_string):\n",
    "    missing_directories = []\n",
    "\n",
    "    for subdir in os.listdir(root_directory):\n",
    "        subdirectory_path = os.path.join(root_directory, subdir)\n",
    "        file_path = os.path.join(subdirectory_path, target_file)\n",
    "\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()\n",
    "                if search_string not in file_content:\n",
    "                    missing_directories.append(subdirectory_path)\n",
    "\n",
    "    return missing_directories\n",
    "\n",
    "root_directory = rootdir\n",
    "target_file = \"sources_every_bkgreg_fk5.reg\"\n",
    "search_string = \"annu\"\n",
    "\n",
    "missing_directories = check_for_string_in_file(root_directory, target_file, search_string)\n",
    "\n",
    "if missing_directories:\n",
    "    print(\"Subdirectories without the string 'annu' in the file:\")\n",
    "    for directory in missing_directories:\n",
    "        print(directory)\n",
    "else:\n",
    "    print(\"All subdirectories have the string 'annu' in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create mask log\n",
    "import pandas as pd\n",
    "\n",
    "# f = open(f'{datapath}/cal_regionarea.sh', 'w')\n",
    "CDELT = 6.94E-04 * 60 # arcmin per pixel\n",
    "\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG4936')\n",
    "srclst = []\n",
    "bkglst = []\n",
    "for homepath in homepaths:\n",
    "    os.chdir(homepath)\n",
    "    if os.path.exists('sources_every_srcreg_fk5.reg'):\n",
    "        if os.path.isdir(f'{homepath}/srcs_regions'):\n",
    "            os.chdir(f'{homepath}/srcs_regions')\n",
    "\n",
    "            srcfiles = glob('fk5_src*reg')\n",
    "            num = len(srcfiles)\n",
    "            newf = open('cal_areaxsec.sh', 'w')\n",
    "\n",
    "\n",
    "            for pref in ['mos1', 'mos2', 'pn']:\n",
    "\n",
    "                for i in range(1,num+1):\n",
    "                    srcreg = f'fk5_src_{int(i)}.reg'\n",
    "                    bkgreg = f'fk5_bkg_{int(i)}.reg'\n",
    "\n",
    "                    # newf.write(f'rm {srcreg.split(\".\")[0]}_{name}_msk.fits\\n')\n",
    "                    # newf.write(f'rm {bkgreg.split(\".\")[0]}_{name}_msk.fits\\n')\n",
    "                    # newf.write(f'rm {srcreg.split(\".\")[0]}_{name}_msk_exp.fits\\n')\n",
    "                    # newf.write(f'rm {bkgreg.split(\".\")[0]}_{name}_msk_exp.fits\\n')\n",
    "                    # newf.write(f'rm {srcreg.split(\".\")[0]}_{name}_msk.log\\n')\n",
    "                    # newf.write(f'rm {bkgreg.split(\".\")[0]}_{name}_msk.log\\n')\n",
    "\n",
    "                    namefile = glob(f'../{pref}*-expimsky-350-2000.fits')[0]\n",
    "                    name = namefile.split('/')[-1].split('-')[0]\n",
    "                    newf.write(f'ftimgcalc {srcreg.split(\".\")[0]}_{name}_msk.fits \\'regfilter(\"{srcreg}\",A.P1,A.P2) ? (1):(0)\\' a=../{name}-expimsky-350-2000.fits clobber=yes\\n')\n",
    "                    newf.write(f'ftimgcalc {bkgreg.split(\".\")[0]}_{name}_msk.fits \\'regfilter(\"{bkgreg}\",A.P1,A.P2) ? (1):(0)\\' a=../{name}-expimsky-350-2000.fits clobber=yes\\n')\n",
    "\n",
    "                    newf.write(f'farith {srcreg.split(\".\")[0]}_{name}_msk.fits ../{name}-expimsky-350-2000.fits {srcreg.split(\".\")[0]}_{name}_msk_exp.fits \"*\"\\n')\n",
    "                    newf.write(f'farith {bkgreg.split(\".\")[0]}_{name}_msk.fits ../{name}-expimsky-350-2000.fits {bkgreg.split(\".\")[0]}_{name}_msk_exp.fits \"*\"\\n')\n",
    "\n",
    "                    newf.write(f'fimgstat {srcreg.split(\".\")[0]}_{name}_msk_exp.fits threshlo=I threshup=I > {srcreg.split(\".\")[0]}_{name}_msk.log\\n')\n",
    "                    newf.write(f'fimgstat {bkgreg.split(\".\")[0]}_{name}_msk_exp.fits threshlo=I threshup=I > {bkgreg.split(\".\")[0]}_{name}_msk.log\\n')\n",
    "\n",
    "            newf.close()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make area csv ###\n",
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "srclst = []\n",
    "bkglst = []\n",
    "\n",
    "for i, homepath in enumerate(homepaths):\n",
    "    if os.path.exists(f'{homepath}/srcs_regions'):\n",
    "        os.chdir(f'{homepath}/srcs_regions')\n",
    "        matching_files = glob('*msk.log')\n",
    "        if matching_files:\n",
    "            srcfiles = glob('fk5_src*reg')\n",
    "            num = len(srcfiles)\n",
    "            try:\n",
    "                for pref in ['mos1', 'mos2', 'pn']:\n",
    "                    namefile = glob(f'../{pref}*-expimsky-350-2000.fits')[0]\n",
    "                    name = namefile.split('/')[-1].split('-')[0]\n",
    "                    dir = {}\n",
    "                    dir['srcidx'] = np.arange(1,num+1)\n",
    "                    dir['srcarea[pixel]'] = np.zeros(int(num))\n",
    "                    dir['bkgarea[pixel]'] = np.zeros(int(num))\n",
    "\n",
    "                    for i in range(1,num+1):\n",
    "                        srcreg = f'fk5_src_{int(i)}.reg'\n",
    "                        bkgreg = f'fk5_bkg_{int(i)}.reg'\n",
    "                        \n",
    "                        f = open(f'{srcreg.split(\".\")[0]}_{name}_msk.log')\n",
    "                        lines = f.readlines()[:]\n",
    "                        f.close()\n",
    "                        for line in lines:\n",
    "                            if 'sum' in line:\n",
    "                                dir['srcarea[pixel]'][int(i-1)] = float(line.split('=')[-1])\n",
    "\n",
    "                        f = open(f'{bkgreg.split(\".\")[0]}_{name}_msk.log')\n",
    "                        lines = f.readlines()[:]\n",
    "                        f.close()\n",
    "                        for line in lines:\n",
    "                            if 'sum' in line:\n",
    "                                dir['bkgarea[pixel]'][int(i-1)] = float(line.split('=')[-1])\n",
    "\n",
    "                    df = pd.DataFrame(dir)\n",
    "                    df.to_csv(f'sources_areasxsec_{pref}.csv', index=False)\n",
    "                        # backexp=\"{bkgtxt}\"\n",
    "                    \n",
    "                    #### tidy csv to dats dir ####\n",
    "                    datpath = f'{rootdir}/dats/logNS'\n",
    "                    srcname = homepath.split('/')[-1]\n",
    "                    df.to_csv(f'{datpath}/{srcname}_sources_areasxsec_{pref}.csv', index=False)\n",
    "            except:\n",
    "                print(homepath)\n",
    "        else:\n",
    "            print(homepath)\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepaths = glob('/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/SDSSTG*')\n",
    "srclst = []\n",
    "bkglst = []\n",
    "for homepath in homepaths:\n",
    "    os.chdir(homepath)\n",
    "    if os.path.exists('sources_every_srcreg_fk5.reg'):\n",
    "        if os.path.isdir(f'{homepath}/srcs_regions'):\n",
    "            os.chdir(f'{homepath}/srcs_regions')\n",
    "\n",
    "            f = open(f'gen_rmf.sh', 'w')\n",
    "\n",
    "            specfiles = glob('src_1_*_spec.pi')\n",
    "\n",
    "            for specfile in specfiles:\n",
    "                \n",
    "                if 'mos1' in specfile:\n",
    "                    badpix_file = f'../mos1S001-fovimsky-350-8000.fits'\n",
    "                elif 'mos2' in specfile:\n",
    "                    badpix_file = f'../mos2S002-fovimsky-350-8000.fits'\n",
    "                else:\n",
    "                    badpix_file = f'../pnS003-fovimsky-350-8000.fits'\n",
    "\n",
    "                f.write(f'''\n",
    "            rmfgen spectrumset={specfile} rmfset={specfile.split('.')[0]}.rmf detmaptype=flat extendedsource=yes badpixlocation={badpix_file}\\n\n",
    "                    ''') \n",
    "\n",
    "            f.close()\n",
    "\n",
    "\n",
    "            # arfgen spectrumset=source_{inst}_{obs}_bkg_spec_bin5.fits {set3} rmfset=source_{inst}_{obs}_bkg.rmf arfset=source_{inst}_{obs}_bkg.arf badpixlocation={inst}_hiband_loband_clean_fov.fits\\n\n",
    "            #     for reg in ['oofov']:#['reg1', 'reg2', 'reg3', 'reg4', 'reg5']:\n",
    "            #         f.write(f'''\n",
    "            # rmfgen spectrumset=source_{inst}_{obs}_{reg}_spec_bin.fits rmfset=source_{inst}_{obs}_{reg}.rmf detmaptype=flat extendedsource=yes badpixlocation={inst}_hiband_loband_clean_fov.fits\\n\n",
    "            #         ''')# arfgen spectrumset=source_{inst}_{obs}_{reg}_spec.fits {set3} rmfset=source_{inst}_{obs}_{reg}.rmf arfset=source_{inst}_{obs}_{reg}.arf badpixlocation={inst}_hiband_loband_clean_fov.fits\\n\n",
    "\n",
    "            # f = open(f'gen_arf_rmf_{obs}.sh')\n",
    "            # print(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 determine the excluded point sources cutoff flux\n",
    "\n",
    "get counts rate from the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ctr(PATH):\n",
    "    os.chdir(PATH)\n",
    "    os.getcwd()\n",
    "    \n",
    "    srcspec_set = glob('src_*_*_spec.pi')\n",
    "    bkgspec_set = glob('bkg_*_*_spec.pi')\n",
    "    num = len(glob('src_*_mos1_spec.pi'))\n",
    "\n",
    "    totctr_dict = {}\n",
    "    srcctr_dict = {}\n",
    "\n",
    "    for j, name in enumerate(['mos1', 'mos2', 'pn']):\n",
    "        # read the s* arcmin2\n",
    "        areafile = glob(f'sources_areasxsec_{name}.csv')[0]\n",
    "        df = pd.read_csv(areafile)\n",
    "        srcarea = df['srcarea[pixel]']\n",
    "        bkgarea = df['bkgarea[pixel]']\n",
    "\n",
    "        src_cts = np.zeros(int(num))\n",
    "        bkg_cts = np.zeros(int(num))\n",
    "\n",
    "        for i in range(1, num+1):\n",
    "            srcspec = f'src_{i}_{name}_spec.pi'\n",
    "            bkgspec = f'bkg_{i}_{name}_spec.pi'\n",
    "            if (srcspec in srcspec_set) & (bkgspec in bkgspec_set):\n",
    "                f = fits.open(f'{srcspec}')\n",
    "                src_spec = f[1].data\n",
    "                src_cts[int(i-1)] = np.sum(src_spec['COUNTS'])\n",
    "\n",
    "                f = fits.open(f'{bkgspec}')\n",
    "                bkg_spec = f[1].data\n",
    "                bkg_cts[int(i-1)] = np.sum(bkg_spec['COUNTS'])     \n",
    "            else:\n",
    "                src_cts[int(i-1)] = 0\n",
    "                bkg_cts[int(i-1)] = 0\n",
    "\n",
    "        srcctr = src_cts/(srcarea)\n",
    "        srcctr[~np.isfinite(srcctr)] = np.nan\n",
    "        bkgctr = bkg_cts/(bkgarea)\n",
    "        bkgctr[~np.isfinite(bkgctr)] = np.nan\n",
    "        ### in order cores have been included in bkg region\n",
    "        bkgnewctr = np.where(bkgctr > (2/3*srcctr), np.nanmedian(bkgctr), bkgctr)\n",
    "        totctr_dict[name] = srcctr-bkgnewctr\n",
    "        srcctr_dict[name] = srcctr\n",
    "        \n",
    "    totctr_dict['pn'] = totctr_dict['pn']/13.55 * 4.907\n",
    "    srcctr_dict['pn'] = srcctr_dict['pn']/13.55 * 4.907\n",
    "    return totctr_dict, srcctr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_logN_logS(data_df, savepath, savefile, detect_lim):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 4)) \n",
    "    for name in ['mos1', 'mos2', 'pn']: # \n",
    "        if 'pn' in name:\n",
    "            axs[0].plot(np.arange(len(data_df[name])), data_df[name]/13.55 * 4.907, alpha = 0.5, label = name)\n",
    "        else:\n",
    "            axs[0].plot(np.arange(len(data_df[name])), data_df[name], alpha = 0.5, label = name)\n",
    "\n",
    "    v = np.nanmax(data_df, axis=1)\n",
    "    v1 = np.nansum(data_df, axis=1)\n",
    "    axs[0].plot(np.arange(len(data_df[name])), v, 'r--', label = 'max')\n",
    "    axs[0].plot(np.arange(len(data_df[name])), v1, 'b--', label = 'sum')\n",
    "    axs[0].legend()\n",
    "\n",
    "\n",
    "    \n",
    "    hist, bin = np.histogram(v, bins = np.logspace(-6, np.log10(np.nanmax(v)), 30))\n",
    "    axs[1].stairs(hist, bin, label = 'max', color ='r', linestyle = '--')\n",
    "    axs[2].stairs(np.cumsum(hist[::-1])[::-1], bin, label = 'max', color ='r', linestyle = '--')\n",
    "    hist, bin = np.histogram(v1, bins = np.logspace(-6, np.log10(np.nanmax(v)), 30))\n",
    "    axs[1].stairs(hist, bin, label = 'sum', color = 'b')\n",
    "    axs[2].stairs(np.cumsum(hist[::-1])[::-1], bin, label = 'sum', color ='b')\n",
    "\n",
    "    axs[1].legend()\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].axvline(detect_lim, c = 'r', linestyle = 'dashed')\n",
    "    axs[0].axhline(detect_lim, c = 'r', linestyle = 'dashed')\n",
    "    axs[2].axvline(detect_lim, c = 'r', linestyle = 'dashed')\n",
    "\n",
    "    axs[1].axvline(detect_lim, c = 'b')\n",
    "    axs[0].axhline(detect_lim, c = 'b')\n",
    "    axs[2].axvline(detect_lim, c = 'b')\n",
    "\n",
    "    axs[1].set_title('hist')\n",
    "    axs[1].set_xscale('log')\n",
    "    axs[1].set_ylabel('N')\n",
    "    axs[1].set_xlabel('S (bg subtracted) [cts/s/pixel]')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].set_xlabel('src idx')\n",
    "    axs[0].set_ylabel('S (bg subtracted) [cts/s/pixel]')\n",
    "\n",
    "    axs[2].set_title('logN-logS')\n",
    "    axs[2].set_xscale('log')\n",
    "    axs[2].set_yscale('log')\n",
    "    axs[2].set_ylabel('N')\n",
    "    axs[2].set_xlabel('S (bg subtracted) [cts/s/pixel]')\n",
    "    axs[2].legend()\n",
    "\n",
    "    plt.savefig(f'{savepath}/{savefile}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1 give a dummy detection limit, plot all sources and view all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#### basic parameters ####\n",
    "flux2cts = [4.907, 4.907, 13.55] # thin\n",
    "sens = [1.15e-6, 1.28e-6, 1.78e-6]\n",
    "\n",
    "#### save and plot ctr ####\n",
    "rootdir = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP'\n",
    "homepaths = glob(f'{rootdir}/SDSSTG9695')\n",
    "\n",
    "\n",
    "figpath = f'{rootdir}/figs/logNS'\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "os.makedirs(figpath, exist_ok=True)\n",
    "os.makedirs(datpath, exist_ok=True)\n",
    "\n",
    "fin_files = glob(f'{datpath}/*')\n",
    "fin_names = np.array([fin_file.split('_')[0] for fin_file in fin_files])\n",
    "all_names = np.array([homepath.split('/')[-1] for homepath in homepaths])\n",
    "unfin_names = np.setdiff1d(all_names, fin_names)\n",
    "print(unfin_names)\n",
    "\n",
    "srclst = []\n",
    "bkglst = []\n",
    "for srcname in unfin_names:\n",
    "    os.chdir(f'{rootdir}/{srcname}')\n",
    "    print(f'{rootdir}/{srcname}')\n",
    "    if os.path.exists('sources_every_srcreg_fk5.reg'):\n",
    "        if os.path.isdir(f'{rootdir}/{srcname}/srcs_regions'):\n",
    "            totctr_dict,srcctr_dict = get_ctr(f'{rootdir}/{srcname}/srcs_regions') \n",
    "            df1 = pd.DataFrame(totctr_dict)\n",
    "            df1.to_csv(f'{datpath}/{srcname}_totctr.csv')\n",
    "            df2 = pd.DataFrame(srcctr_dict)\n",
    "            df2.to_csv(f'{datpath}/{srcname}_srcctr.csv')\n",
    "\n",
    "            plot_logN_logS(df1, f'{figpath}/totctr', f'{srcname}_totctr', 1.3e-6)\n",
    "            plot_logN_logS(df2, f'{figpath}/srcctr', f'{srcname}_srcctr', 2e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2 plot the assigned detetction limit on\n",
    "and get ctr and area from the dats dir instead of srcs_regions dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#### basic parameters ####\n",
    "flux2cts = [4.907, 4.907, 13.55] # thin\n",
    "sens = [1.15e-6, 1.28e-6, 1.78e-6]\n",
    "\n",
    "#### load detection limits ####\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "dat_f = pd.read_csv(f'{datpath}/readme.csv')\n",
    "\n",
    "#### save and plot ctr ####\n",
    "rootdir = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP'\n",
    "homepaths = glob(f'{rootdir}/SDSSTG*')\n",
    "figpath = f'{rootdir}/figs/logNS/final'\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "os.makedirs(figpath, exist_ok=True)\n",
    "os.makedirs(datpath, exist_ok=True)\n",
    "all_names = [homepath.split('/')[-1] for homepath in homepaths]\n",
    "srclst = []\n",
    "bkglst = []\n",
    "for srcname in all_names:\n",
    "    msk = dat_f['SRCID']==srcname\n",
    "    if np.sum(msk)>0:\n",
    "        detect_lim = np.array(dat_f['detection_limit'])[msk][0]\n",
    "        if os.path.exists(f'{rootdir}/{srcname}/sources_every_srcreg_fk5.reg'):\n",
    "            if os.path.isdir(f'{rootdir}/{srcname}/srcs_regions'):\n",
    "                totctr_dict = pd.read_csv(f'{datpath}/{srcname}_totctr.csv')\n",
    "                plot_logN_logS(df1, f'{figpath}', f'{srcname}_totctr', detect_lim)\n",
    "    else:\n",
    "        print(srcname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 edit the emllist_final.fits\n",
    "1) throw away the point sources under the cutoff limit \n",
    "cutoff limit is 3.0e-6 cts/s/pixel in mos, 7e-6 in pn\n",
    "2) last adjust the size\n",
    "3) check the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 throw away the point sources under the cutoff limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rootdir = '/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/'\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "dat_f = pd.read_csv(f'{datpath}/readme.csv')\n",
    "\n",
    "# read detection limit\n",
    "\n",
    "\n",
    "for i, ID in enumerate(dat_f['SRCID']): \n",
    "    detect_lim = dat_f['detection_limit'][i]\n",
    "    ctr_f = pd.read_csv(f'{datpath}/{ID}_totctr.csv')\n",
    "    vmax = np.nanmax(ctr_f, axis=1)\n",
    "    msk = vmax>detect_lim\n",
    "\n",
    "    sel_idx = list(np.arange(len(vmax))[msk])\n",
    "    os.chdir(f'{rootdir}/{ID}')\n",
    "\n",
    "    print(f'{rootdir}/{ID}')\n",
    "    with open(f'sources_every_srcreg_fk5.reg') as f:\n",
    "        lines = f.readlines()[3:]\n",
    "\n",
    "    with open(f'sources_final_sum_srcreg_fk5.reg', 'w') as newf:\n",
    "        newf.write('global color=cyan dashlist=8 3 width=2 font=\"helvetica 12 normal roman\" select=1 highlite=1 dash=0 fixed=0 edit=1 move=1 delete=1 include=1 source=1 \\n')\n",
    "        newf.write('fk5\\n')\n",
    "        \n",
    "        for i in range(len(sel_idx)):\n",
    "            newf.write(lines[sel_idx[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.2 Last check the sum*final*reg! -> sum*final*edit.reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP'\n",
    "datapath = f'{rootdir}/dom'\n",
    "\n",
    "\n",
    "with fits.open(f'{datapath}/xgap_m500_forecast.fits') as f:\n",
    "    dat = f[1].data\n",
    "    doc_ids = dat['ID']\n",
    "\n",
    "all_ids = np.array([f.split('/')[-1].split('G')[-1] for f in glob(f'{rootdir}/SDSS*')]).astype(int)\n",
    "# fin_ids = np.array([f.split('/')[-1].split('.')[0].split('G')[-1] for f in glob(f'{rootdir}/figs/srcs_final_resize_05/*.png')]).astype(int)\n",
    "miss_ids = all_ids[~np.isin(all_ids, doc_ids)]\n",
    "\n",
    "ids = miss_ids\n",
    "# ids = [22635]\n",
    "for i in range(len(ids)):\n",
    "    subdir = f\"{rootdir}/SDSSTG{ids[i]}\"\n",
    "    savepath = f'{rootdir}/figs/srcs_final_resize_05'\n",
    "    os.makedirs(savepath, exist_ok = True)\n",
    "    if os.path.exists(subdir):\n",
    "        os.chdir(subdir)\n",
    "        os.system(f\"rm {savepath}/SDSSTG{ids[i]}.png\")\n",
    "        os.system(f'ds9 comb-fovimsky-350-2000.fits -region sources_final_sum_srcreg_fk5.reg -region emllist_every.reg -region R500_01_fk5.reg -scale log -cmap b -smooth yes -colorbar no -zoom to fit &')\n",
    "        os.system(f'sleep 5')\n",
    "        os.system(f\"xpaset -p ds9 saveimage png {savepath}/SDSSTG{ids[i]}.png\")\n",
    "        os.system(f\"xpaset -p ds9 exit\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPEN check the missing ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(f'{datapath}/xgap_m500_forecast.fits') as f:\n",
    "    dat = f[1].data\n",
    "    doc_ids = dat['ID']\n",
    "all_ids = np.array([f.split('/')[-1].split('G')[-1] for f in glob(f'{rootdir}/SDSS*')]).astype(int)\n",
    "fin_ids = np.array([f.split('/')[-1].split('.')[0].split('G')[-1] for f in glob(f'{rootdir}/figs/srcs_final_resize_05/*.png')]).astype(int)\n",
    "miss_ids = all_ids[~np.isin(all_ids, fin_ids)]\n",
    "docmiss_ids = all_ids[~np.isin(all_ids, doc_ids)]\n",
    "print(miss_ids)\n",
    "print(docmiss_ids)\n",
    "print(len(doc_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.3 resize the regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ctr from csv, compare with detect lim\n",
    "resize_scale = 0.5\n",
    "rootdir = '/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/'\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "dat_f = pd.read_csv(f'{datpath}/readme.csv')\n",
    "\n",
    "ids = dat_f['SRCID']\n",
    "\n",
    "for i, ID in enumerate(ids): \n",
    "    detect_lim = dat_f['detection_limit'][i]\n",
    "    ctr_f = pd.read_csv(f'{datpath}/{ID}_totctr.csv')\n",
    "    vmax = np.nanmax(ctr_f, axis=1)\n",
    "    msk = vmax>detect_lim\n",
    "\n",
    "    sel_idx = list(np.arange(len(vmax))[msk])\n",
    "    os.chdir(f'{rootdir}/{ID}')\n",
    "\n",
    "    print(f'{rootdir}/{ID}')\n",
    "    with open(f'sources_every_srcreg_fk5.reg') as f:\n",
    "        lines = f.readlines()[3:]\n",
    "        \n",
    "\n",
    "    with open(f'sources_final_sum_srcreg_fk5.reg', 'w') as newf:\n",
    "        newf.write('global color=cyan dashlist=8 3 width=2 font=\"helvetica 12 normal roman\" select=1 highlite=1 dash=0 fixed=0 edit=1 move=1 delete=1 include=1 source=1 \\n')\n",
    "        newf.write('fk5\\n')\n",
    "        \n",
    "        for i in range(len(sel_idx)):\n",
    "            line = lines[sel_idx[i]]\n",
    "            r1 = float(line.split(',')[-2][:-1]) * resize_scale\n",
    "            r2 = float(line.split(',')[-3][:-1]) * resize_scale\n",
    "            line_segs = line.split(',')[:]\n",
    "            newline = f'{line_segs[0]},{line_segs[1]},{r1}\",{r2}\",{line_segs[-1]}'\n",
    "            newf.write(newline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 2nd and last run of region command\n",
    "\n",
    "if consider region command in cheese, \n",
    "this is actually the 3rd time to run region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create emllist_final.fits, to convert the centers of fk5 coords to detxy and xy coords\n",
    "rootdir = '/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/'\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "dat_f = pd.read_csv(f'{datpath}/readme.csv')\n",
    "\n",
    "# ids = dat_f['SRCID']\n",
    "ids = ['SDSSTG40241']\n",
    "for ID in tqdm(ids): \n",
    "    os.chdir(f'{rootdir}/{ID}')\n",
    "    filename = f'emllist_final.fits'\n",
    "    os.system(f'cp emllist.fits {filename}')\n",
    "\n",
    "    f = fits.open(filename)\n",
    "    dat = f[1].data\n",
    "    f.close()\n",
    "    dat['FLAG'] = 0\n",
    "\n",
    "    # load the styles of the recarray data \n",
    "    sample_dype = dat.dtype\n",
    "    sample = dat[0]\n",
    "\n",
    "    # load the regions of complete pointsources\n",
    "    srcname = f'sources_final_sum_srcreg_fk5_edit.reg'\n",
    "    regfile = open(srcname)\n",
    "    lines = regfile.readlines()[:]\n",
    "    regfile.close()\n",
    "\n",
    "    num = len(lines)-3\n",
    "    dat = dat[:num]\n",
    "\n",
    "    for i, f in enumerate(lines[3:]):\n",
    "        if len(f) > 1:\n",
    "            ra = f.split('(')[-1].split(',')[0]\n",
    "            dec = f.split(',')[1]\n",
    "            dat[i]['RA'] = ra\n",
    "            dat[i]['DEC'] = dec\n",
    "            dat[i]['ML_ID_SRC'] = int(i+1)\n",
    "            dat[i]['DIST_NN'] = 1000\n",
    "            dat[i]['DET_ML'] = 20\n",
    "            dat[i]['BOX_ID_SRC'] = int(i+1)\n",
    "            dat[i]['ID_INST'] = 0\n",
    "            dat[i]['ID_BAND'] = 0\n",
    "            dat[i]['ID_CLUSTER'] = int(i+1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    newf = fits.open(f'{filename}', mode='update')\n",
    "    newf['SRCLIST'].data = dat\n",
    "    newf.flush()\n",
    "    newf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## edit region files\n",
    "\n",
    "# create emllist_final.fits, to convert the centers of fk5 coords to detxy and xy coords\n",
    "rootdir = '/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/'\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "dat_f = pd.read_csv(f'{datpath}/readme.csv')\n",
    "\n",
    "# ids = dat_f['SRCID']\n",
    "ids = ['SDSSTG40241']\n",
    "for ID in tqdm(ids): \n",
    "    os.chdir(f'{rootdir}/{ID}')\n",
    "    os.makedirs('cheese_old', exist_ok=True)\n",
    "    f = open(f'region_2nd.sh', 'w')\n",
    "\n",
    "    f.write(\n",
    "    '''\n",
    "source set_sas.txt\n",
    "export M1=mos1\n",
    "export M2=mos2\n",
    "export PN=pn\n",
    "export elo=350\n",
    "export ehi=8000\n",
    "\n",
    "for name in $M1 $M2 $PN\n",
    "do\n",
    "\n",
    "region eventset=${name}-allevc-exchips.fits operationstyle=global srclisttab=emllist_final.fits:SRCLIST expression=\"(ID_INST == 0)&&(DET_ML >= 1)\" bkgregionset=${name}-bkgregtdet.fits bkgfraction=0.1 radiusstyle=contour outunit=detxy verbosity=4 2>&1 | tee region-det-${name}_2nd.log\n",
    "region eventset=${name}-allevc-exchips.fits operationstyle=global srclisttab=emllist_final.fits:SRCLIST expression=\"(ID_INST == 0)&&(DET_ML >= 1)\" bkgregionset=${name}-bkgregtsky.fits bkgfraction=0.1 radiusstyle=contour outunit=xy verbosity=4 2>&1 | tee region-sky-${name}_2nd.log\n",
    "\n",
    "mv ${name}-bkgregtdet.fits ${name}-bkgregtdet_coords.fits\n",
    "mv ${name}-bkgregtsky.fits ${name}-bkgregtsky_coords.fits\n",
    "\n",
    "done\n",
    "\n",
    "    '''\n",
    "    )\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alter the radius in *-bkgregtdet.fits and *-bkgregtsky.fits\n",
    "rootdir = '/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/'\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "dat_f = pd.read_csv(f'{datpath}/readme.csv')\n",
    "\n",
    "# ids = dat_f['SRCID']\n",
    "ids = ['SDSSTG40241']\n",
    "for ID in tqdm(ids): \n",
    "    os.chdir(f'{rootdir}/{ID}')\n",
    "    as2det = 20 # 1arcsec to detxy or xy\n",
    "\n",
    "    for name in ['mos1', 'mos2', 'pn']:\n",
    "        fname_det = f'{name}-bkgregtdet_coords.fits'\n",
    "        fname_sky = f'{name}-bkgregtsky_coords.fits'\n",
    "        \n",
    "        for filename in [fname_det, fname_sky]:\n",
    "            os.system(f'''cp {filename} {filename.split('_')[0]}.fits''')\n",
    "\n",
    "            f = fits.open(filename)\n",
    "            dat = f[1].data\n",
    "            f.close()\n",
    "\n",
    "            # load the styles of the recarray data \n",
    "            sample_dype = dat.dtype\n",
    "            sample = dat[0]\n",
    "\n",
    "            # load the regions of complete pointsources\n",
    "            srcname = f'sources_final_sum_srcreg_fk5_edit.reg'\n",
    "            regfile = open(srcname)\n",
    "            lines = regfile.readlines()[:]\n",
    "            regfile.close()\n",
    "\n",
    "            num = len(lines)-3\n",
    "            dat = dat[:num]\n",
    "\n",
    "            for i, f in enumerate(lines[3:]):\n",
    "                if len(f) > 1:\n",
    "                    if 'circle' in f:\n",
    "                        r = float(f.split(',')[-1].split(')')[0][:-1]) * as2det\n",
    "                        dat[int(i)]['R'] = [r, r, 0, 0]\n",
    "                    elif 'ellipse' in f:\n",
    "                        r2 = float(f.split(',')[-2][:-1]) * as2det\n",
    "                        r1 = float(f.split(',')[-3][:-1]) * as2det\n",
    "                        rot = float(f.split(',')[-1].split(')')[0][:-1])\n",
    "                        dat[int(i)]['R'] = [r1, r2, 0, 0]\n",
    "                        dat[int(i)]['ROTANG'] = [rot, 0, 0, 0]\n",
    "\n",
    "                    else:\n",
    "                        raise ValueError('Wrong shape, check the region file!')\n",
    "                else:\n",
    "                    continue\n",
    "            newf = fits.open(f'''{filename.split('_')[0]}.fits''', mode='update')\n",
    "            newf['REGION'].data = dat\n",
    "            newf.flush()\n",
    "            newf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the *bkgregtsky.fits to region file\n",
    "# the physical coordinates in mos1S001,mos2S002,pnS003-bkgregtsky should be the same\n",
    "rootdir = '/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/'\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "dat_f = pd.read_csv(f'{datpath}/readme.csv')\n",
    "\n",
    "# ids = dat_f['SRCID']\n",
    "ids = ['SDSSTG40241']\n",
    "for ID in tqdm(ids): \n",
    "    os.chdir(f'{rootdir}/{ID}')\n",
    "    for name in ['mos1', 'mos2', 'pn']:\n",
    "        data_f = fits.open(f'{name}-bkgregtsky.fits')\n",
    "        dat = data_f[1].data\n",
    "\n",
    "        f = open(f'{name}-bkgregtsky.reg','w')\n",
    "        f.write('physical\\n')\n",
    "        for i in range(len(dat)):\n",
    "            f.write(f'''ellipse({dat[i]['X'][0]},{dat[i]['Y'][0]},{dat[i]['R'][0]},{dat[i]['R'][1]},{dat[i]['ROTANG'][0]})\\n''')\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.1 final check the regions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP'\n",
    "datapath = f'{rootdir}/dom'\n",
    "\n",
    "\n",
    "with fits.open(f'{datapath}/xgap_m500_forecast.fits') as f:\n",
    "    dat = f[1].data\n",
    "    doc_ids = dat['ID']\n",
    "\n",
    "all_ids = np.array([f.split('/')[-1].split('G')[-1] for f in glob(f'{rootdir}/SDSS*')]).astype(int)\n",
    "# fin_ids = np.array([f.split('/')[-1].split('.')[0].split('G')[-1] for f in glob(f'{rootdir}/figs/srcs_final_resize_05/*.png')]).astype(int)\n",
    "miss_ids = all_ids[~np.isin(all_ids, doc_ids)]\n",
    "\n",
    "# ids = all_ids\n",
    "ids = ['40241']\n",
    "for i in range(len(ids)):\n",
    "    subdir = f\"{rootdir}/SDSSTG{ids[i]}\"\n",
    "    savepath = f'{rootdir}/figs/last_check'\n",
    "    os.makedirs(savepath, exist_ok = True)\n",
    "    if os.path.exists(subdir):\n",
    "        os.chdir(subdir)\n",
    "        os.system(f\"rm {savepath}/SDSSTG{ids[i]}.png\")\n",
    "        os.system(f'ds9 pnS003-fovimsky-350-2000.fits -region sources_final_sum_srcreg_fk5_edit.reg -region pn-bkgregtsky.reg -region R500_01_fk5.reg -scale log -cmap b -smooth yes -colorbar no -zoom to fit &')\n",
    "        os.system(f'sleep 5')\n",
    "        os.system(f\"xpaset -p ds9 saveimage png {savepath}/SDSSTG{ids[i]}.png\")\n",
    "        os.system(f\"xpaset -p ds9 exit\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.2 make mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:00<00:00, 339.17it/s]\n"
     ]
    }
   ],
   "source": [
    "## make mask!\n",
    "rootdir = '/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP/'\n",
    "datpath = f'{rootdir}/dats/logNS'\n",
    "dat_f = pd.read_csv(f'{datpath}/readme.csv')\n",
    "\n",
    "ids = dat_f['SRCID']\n",
    "# ids = ['SDSSTG40241']\n",
    "\n",
    "for ID in tqdm(ids): \n",
    "    os.chdir(f'{rootdir}/{ID}')\n",
    "    f = open(f'makemask_2nd.sh', 'w')\n",
    "    for name in ['mos1', 'mos2', 'pn']:\n",
    "        imgfile = glob(f'{name}*-fovimsky-350-2000.fits')[0]\n",
    "        mskfile = glob(f'{name}*-fovimtmask.fits')[0]\n",
    "        longname = mskfile.split('-')[0]\n",
    "        f.write(f'''\n",
    "makemask imagefile={imgfile} maskfile={mskfile} regionfile={longname}-bkgregtsky.fits cheesefile={longname}-cheeset.fits 2>&1 | tee makemask-{name}_2nd.log\n",
    "        ''')\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.2 check *-cheeset.fits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n",
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n",
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n",
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n",
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n",
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    }
   ],
   "source": [
    "rootdir = f'/Users/eusracenorth/Documents/work/XGAP-ABUN/alldata/XGAP'\n",
    "datapath = f'{rootdir}/dom'\n",
    "\n",
    "\n",
    "with fits.open(f'{datapath}/xgap_m500_forecast.fits') as f:\n",
    "    dat = f[1].data\n",
    "    doc_ids = dat['ID']\n",
    "\n",
    "all_ids = np.array([f.split('/')[-1].split('G')[-1] for f in glob(f'{rootdir}/SDSS*')]).astype(int)\n",
    "# fin_ids = np.array([f.split('/')[-1].split('.')[0].split('G')[-1] for f in glob(f'{rootdir}/figs/srcs_final_resize_05/*.png')]).astype(int)\n",
    "miss_ids = all_ids[~np.isin(all_ids, doc_ids)]\n",
    "\n",
    "# ids = all_ids\n",
    "ids = ['10159','15354']\n",
    "for i in range(len(ids)):\n",
    "    subdir = f\"{rootdir}/SDSSTG{ids[i]}\"\n",
    "    savepath = f'{rootdir}/figs/cheeset'\n",
    "    os.makedirs(savepath, exist_ok = True)\n",
    "    if os.path.exists(subdir):\n",
    "        os.chdir(subdir)\n",
    "        for name in ['mos1', 'mos2', 'pn']:\n",
    "            if glob(f'{name}-cheeset.fits'):\n",
    "                cheese_file = glob(f'{name}-cheeset.fits')[0]\n",
    "                os.system(f\"rm {savepath}/SDSSTG{ids[i]}_{name}-cheeset.png\")\n",
    "                os.system(f'ds9 {cheese_file} -region {name}-bkgregtsky.reg -scale log -colorbar no -zoom to fit &')\n",
    "                os.system(f'sleep 5')\n",
    "                os.system(f\"xpaset -p ds9 saveimage png {savepath}/SDSSTG{ids[i]}_{name}-cheeset.png\")\n",
    "                os.system(f\"xpaset -p ds9 exit\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.3 comb image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_list(input_list):\n",
    "    order = ['mos1', 'mos2', 'pn']\n",
    "    return sorted(input_list, key=lambda x: (order.index(x[:-4]), x[-4:]))\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "homepaths = glob('/data/yanling/XGAP-ABUN/data/alldata/XGAP/SDSSTG*')\n",
    "\n",
    "for homepath in homepaths:\n",
    "    if os.path.isdir(homepath):\n",
    "        os.chdir(homepath)\n",
    "        f = open('comb_img.sh', 'w')\n",
    "\n",
    "        elo = 500\n",
    "        ehi = 4000\n",
    "\n",
    "        name_dir = {'mos1':'mos1*-allevc', 'mos2':'mos2*-allevc', 'pn':'pn*-allevc'}\n",
    "\n",
    "        express = f'(PATTERN<=4)&&((FLAG & 0xb0000) == 0)&&((FLAG & 0x762a097c) == 0)&&(PI in [{elo}:{ehi}])&&(DETY in [-16510:14345])'\n",
    "        plot_express = f'''imagebinning='imageSize' imagedatatype='Int32' squarepixels=yes ignorelegallimits=yes withxranges=yes withyranges=yes xcolumn='X' ximagesize=900 ximagemax=48400 ximagemin=3401 ycolumn='Y' yimagesize=900 yimagemax=48400 yimagemin=3401'''\n",
    "\n",
    "        name_lst = []\n",
    "        prefix_lst = ''\n",
    "        for file in glob(f'*0*-allevc.fits'):\n",
    "            prefix = file.split('-')[0]\n",
    "            name_lst.append(prefix)\n",
    "        name_lst = reorder_list(name_lst)\n",
    "        for prefix in name_lst:\n",
    "            if 'mos' in prefix:\n",
    "                prefix_lst += f\"{prefix[-5:]}  \"\n",
    "            else:\n",
    "                prefix_lst += f\"{prefix[-4:]}\"\n",
    "        print(prefix_lst)\n",
    "        for name in name_lst:\n",
    "            f.write(f'''source set_sas.txt \\n''')\n",
    "            f.write(f'''source set_chips_on.txt \\n''')\n",
    "            f.write(f'''evselect table={name}-allevc.fits withimageset=Y {plot_express} expression='{express}' imageset='{name}-fovimsky-{elo}-{ehi}.fits'  \\n''')\n",
    "            if 'pn' in name:\n",
    "                f.write(f'''evselect table={name}-allevcoot.fits withimageset=Y {plot_express} expression='{express}' imageset='{name}-fovimootsky-{elo}-{ehi}.fits'  \\n''')\n",
    "            f.write(f'mv {name}-fovimt.fits {name}-fovimsky-{elo}-{ehi}.fits\\n')\n",
    "            f.write(f'cp *expimsky* {name}-expimsky-{elo}-{ehi}.fits\\n')\n",
    "            f.write(f'cp {name[:-4]}-cheeset.fits {name}-cheeset.fits\\n')\n",
    "        f.write(f'''combimage prefixlist=\"{prefix_lst}\" withcheese=yes cheesetype=t elowlist={elo} ehighlist={ehi} > combimg.log 2>&1 \\n ''')\n",
    "        f.write(f'''mv comb-fovimsky-{elo}-{ehi}.fits comb-fovimsky-{elo}-{ehi}_masked.fits\\n''')\n",
    "        f.write(f'''mv comb-expimsky-{elo}-{ehi}.fits comb-expimsky-{elo}-{ehi}_masked.fits\\n''')\n",
    "        f.write(f'''combimage prefixlist=\"{prefix_lst}\" withcheese=no elowlist={elo} ehighlist={ehi} > -a combimg.log 2>&1 \\n ''')\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1302458d99d58fefb56dc0fec08d039cf240bdcae78a53a9226b7c46b3832fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
